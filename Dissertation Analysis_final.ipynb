{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import dis_func as func\n",
    "\n",
    "#import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "cv = KFold(n_splits=10)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import sklearn.metrics as metrics\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded data has 1265993 rows and 56 columns!\n"
     ]
    }
   ],
   "source": [
    "data='keyword.csv'\n",
    "dfo=pd.read_csv(data,sep=',',skiprows=2)\n",
    "df=dfo.copy()\n",
    "print ('Uploaded data has', len(df),'rows and',len(df.columns),'columns!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove column percentages and convert to float\n",
    "def replace_comma(row):\n",
    "    if ',' in row:\n",
    "        return row.replace(',','')\n",
    "    else:\n",
    "        return row\n",
    "    \n",
    "def percent2float(row):\n",
    "    if row.endswith('%'):\n",
    "        return float(row[:-1])/100\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def change_q_scorerow(row):\n",
    "    if row == ' --':\n",
    "        return 0\n",
    "    else:\n",
    "        return float(row)\n",
    "    \n",
    "def change_dash_row(row):\n",
    "    if row == ' --':\n",
    "        return 0\n",
    "    else:\n",
    "        return row\n",
    "\n",
    "#round up conversions\n",
    "#round conversions to 1 if 0<conversions<1, and round down if any other integer\n",
    "def round_conv(row):\n",
    "    if row >0 and row <1:\n",
    "        return 1\n",
    "    else:\n",
    "        return int(row)\n",
    "    \n",
    "# count number of strings and integers in a column\n",
    "def count_str_int(column_name):\n",
    "    string=0\n",
    "    inte=0\n",
    "    floaty=0\n",
    "    unk=0\n",
    "    for i in df[column_name]:\n",
    "        if type(i) == str:\n",
    "            string+=1\n",
    "        elif type(i) == int:\n",
    "            inte+=1\n",
    "        elif type(i) == float:\n",
    "            floaty+=1\n",
    "        else:\n",
    "            unk +=1\n",
    "    print('====================================')\n",
    "    print(column_name)\n",
    "    print(\"There are a total of \",string,\"strings,\",inte,\"integers,\",floaty,\"floats\",unk,\"number of other formats\")\n",
    "    print(\"There are a total of \",string+inte,\"rows in this column\")\n",
    "    print('====================================')\n",
    "    \n",
    "#find number of words\n",
    "def get_number_of_words(row):\n",
    "    return len(row.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain top 80% of keywords\n",
    "cumsum=df.groupby('Search keyword').sum()[['Conversions','Clicks']].sort_values(by='Conversions',ascending=False)\n",
    "cumsum['cum_perc'] = 100*cumsum['Conversions'].cumsum()/cumsum['Conversions'].sum()\n",
    "#top 80% of keywords\n",
    "#filter out top 118 keywords\n",
    "df=df[df['Search keyword'].isin(list((cumsum[cumsum['cum_perc']<80.1])['cum_perc'].index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with zero CPC\n",
    "df=df[df['Avg. CPC']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get number of words column\n",
    "df['No. of words']=df['Search keyword'].apply(func.get_number_of_words)\n",
    "\n",
    "#round up conversions values\n",
    "df['Conversions']=df['Conversions'].apply(func.round_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop ad columns that are useless\n",
    "ad_cols_to_drop=['Headline','Short headline', 'Long headline', 'Responsive Search Ad headline 1','Responsive Search Ad headline 2', 'Responsive Search Ad headline 3','Responsive Search Ad headline 4', 'Responsive Search Ad headline 5','Responsive Search Ad headline 6', 'Responsive Search Ad headline 7', 'Responsive Search Ad headline 8', 'Responsive Search Ad headline 9', 'Responsive Search Ad headline 10', 'Responsive Search Ad headline 11', 'Responsive Search Ad headline 12', 'Responsive Search Ad headline 13','Responsive Search Ad headline 14', 'Responsive Search Ad headline 15','Responsive Search Ad description 1', 'Responsive Search Ad description 2','Responsive Search Ad description 3','Responsive Search Ad description 4', 'Expanded text ad description 2', 'Description line 1','Description line 2','Ad']\n",
    "df=df.drop(df[ad_cols_to_drop],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fill_nan():\n",
    "#     columns_fillna=['Headline','Description line 1','Description line 2','Display URL','Ad']\n",
    "    columns_fillna=['Display URL']\n",
    "    for i in columns_fillna:\n",
    "        df[i]=df[i].fillna('Insuro.co.uk')\n",
    "fill_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combine headline variables:\n",
    "# text_ads_columns=['Headline','Headline 1','Headline 2','Description line 1','Description line 2','Expanded text ad headline 3','Responsive Search Ad headline 1','Responsive Search Ad headline 2','Responsive Search Ad headline 3','Responsive Search Ad headline 4','Responsive Search Ad headline 5','Responsive Search Ad headline 6','Responsive Search Ad description 1','Responsive Search Ad description 2','Responsive Search Ad description 3','Responsive Search Ad description 4','Description','Expanded text ad description 2','Ad']  \n",
    "text_ads_columns=['Headline 1','Headline 2','Expanded text ad headline 3','Description']  \n",
    "landing_page=['Path 1','Path 2']\n",
    "df['text_ads']=''\n",
    "df['landing_page']=''\n",
    "for i in text_ads_columns:\n",
    "    df['text_ads']=df['text_ads']+df[i]\n",
    "for i in landing_page:\n",
    "    df['landing_page']+=df[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop ads and url related columns, along with those with just one variable\n",
    "single_var=[]\n",
    "for i in df.columns:\n",
    "    if df[i].nunique()==1:\n",
    "        single_var.append(i)\n",
    "\n",
    "drop_col_list=text_ads_columns+landing_page+single_var\n",
    "df.drop(drop_col_list,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all text groups and landing page to Ad Group # and Landing Page #\n",
    "# 37 landing page groups\n",
    "# 226 text ad groups\n",
    "text_ad_group=[]\n",
    "landing_page_group=[]\n",
    "for i in list(range(1,df['text_ads'].nunique()+1)):\n",
    "    i='Ad Group '+str(i)\n",
    "    text_ad_group.append(i)\n",
    "\n",
    "for i in list(range(1,df['landing_page'].nunique()+1)):\n",
    "    i='Landing Page Group '+str(i)\n",
    "    landing_page_group.append(i)    \n",
    "    \n",
    "text_ad_group=pd.concat([pd.DataFrame(df['text_ads'].value_counts().sort_values(ascending=False)).reset_index(),pd.DataFrame(text_ad_group)], axis=1).drop(['text_ads'],axis=1).set_index('index').reset_index()\n",
    "text_ad_group.columns=['ad group','Text Ad Group']\n",
    "landing_page_group=pd.concat([pd.DataFrame(df['landing_page'].value_counts().sort_values(ascending=False)).reset_index(),pd.DataFrame(landing_page_group)], axis=1).drop(['landing_page'],axis=1).set_index('index').reset_index()\n",
    "landing_page_group.columns=['landing page','Landing Page']\n",
    "\n",
    "df=pd.merge(df,text_ad_group,left_on='text_ads',right_on='ad group').drop(['text_ads','ad group'],axis=1)\n",
    "df=pd.merge(df,landing_page_group,left_on='landing_page',right_on='landing page').drop(['landing_page','landing page'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize CPC on each keyword\n",
    "#Create Standardized Column\n",
    "avgcpc_stddev=pd.DataFrame(df[df['Conversions']>0].groupby('Search keyword').agg(np.std, ddof=0)['Avg. CPC']).rename(index=str, columns={\"Avg. CPC\": \"Avg. CPC_StdDev\"})\n",
    "avgcpc_mean=pd.DataFrame(df[df['Conversions']>0].groupby('Search keyword').agg(np.mean)['Avg. CPC']).rename(index=str,columns={'Avg. CPC':'Avg. CPC_Mean'})\n",
    "df=pd.merge(df, avgcpc_stddev.join(avgcpc_mean), right_index=True, left_on='Search keyword')\n",
    "df['Avg. CPC_zscore']=(df['Avg. CPC']-df['Avg. CPC_Mean'])/df['Avg. CPC_StdDev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummies (RUN ONCE!)\n",
    "# get_dummies_list=['Search keyword match type','Day of week','Device','Network (with search partners)','Landing page experience','Expected click-through rate','Ad relevance','Ad Group','Landing Page','Display URL']\n",
    "get_dummies_list=['Search keyword match type','Day of week','Device','Network (with search partners)','Landing page experience','Expected click-through rate','Ad relevance','Landing Page','Display URL']\n",
    "\n",
    "df=pd.get_dummies(df, columns=get_dummies_list,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create binary\n",
    "def conv_binary(row):\n",
    "    if row['Conversions'] ==0:\n",
    "        val = 0\n",
    "    elif row['Conversions'] > 0:\n",
    "        val = 1\n",
    "    else:\n",
    "        val=0\n",
    "    return val\n",
    "\n",
    "df['Converted']=df.apply(conv_binary,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-13a7fafb1db9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Run resampling technique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_resam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_resam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_conv_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "#Run resampling technique\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_resam,y_resam=sm.fit_resample(X,y_conv_bin)\n",
    "X_train_resam, X_test_resam, y_train_resam, y_test_resam = train_test_split(X_resam, y_resam, test_size=0.2, random_state=42)\n",
    "\n",
    "clf_conv = LogisticRegression()\n",
    "clf_conv.fit(X_train_resam,y_train_resam)\n",
    "y_pred_resam=clf_conv.predict(X_test_resam)\n",
    "print(accuracy_score(y_test_resam,y_pred_resam))\n",
    "print(confusion_matrix(y_test_resam, y_pred_resam))\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test_resam, y_pred_resam)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=['Search keyword','Campaign','Campaign','Day','Clicks', 'Avg. CPC_StdDev','Avg. CPC_Mean','Ad group',\n",
    "                 'Text Ad Group',\n",
    "                 'Keyword max CPC','Avg. CPC','Impressions', 'CTR', 'Cost','Avg. position', 'Conversions', \n",
    "                 'Cost / conv.','Conv. rate','Converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns_to_drop,axis=1)\n",
    "y=(df['Conversions'])\n",
    "\n",
    "X, X_val, y, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Conversions</td>   <th>  R-squared:         </th>  <td>   0.233</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.233</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   486.6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 29 Jul 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:23:18</td>     <th>  Log-Likelihood:    </th> <td>-2.5414e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 83337</td>      <th>  AIC:               </th>  <td>5.084e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 83285</td>      <th>  BIC:               </th>  <td>5.089e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    52</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                         <td></td>                           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. of words</th>                                   <td>    0.3190</td> <td>    0.012</td> <td>   25.889</td> <td> 0.000</td> <td>    0.295</td> <td>    0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Avg. CPC_zscore</th>                                <td>    0.5073</td> <td>    0.018</td> <td>   28.249</td> <td> 0.000</td> <td>    0.472</td> <td>    0.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Search keyword match type_Exact</th>                <td>   -0.4565</td> <td>    0.044</td> <td>  -10.413</td> <td> 0.000</td> <td>   -0.542</td> <td>   -0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Search keyword match type_Phrase</th>               <td>   -0.0184</td> <td>    0.056</td> <td>   -0.328</td> <td> 0.743</td> <td>   -0.129</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Day of week_Monday</th>                             <td>    0.7220</td> <td>    0.061</td> <td>   11.915</td> <td> 0.000</td> <td>    0.603</td> <td>    0.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Day of week_Saturday</th>                           <td>    0.6054</td> <td>    0.061</td> <td>    9.922</td> <td> 0.000</td> <td>    0.486</td> <td>    0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Day of week_Sunday</th>                             <td>    0.4988</td> <td>    0.061</td> <td>    8.162</td> <td> 0.000</td> <td>    0.379</td> <td>    0.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Day of week_Thursday</th>                           <td>    0.7183</td> <td>    0.061</td> <td>   11.772</td> <td> 0.000</td> <td>    0.599</td> <td>    0.838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Day of week_Tuesday</th>                            <td>    0.7163</td> <td>    0.061</td> <td>   11.831</td> <td> 0.000</td> <td>    0.598</td> <td>    0.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Day of week_Wednesday</th>                          <td>    0.7256</td> <td>    0.061</td> <td>   11.886</td> <td> 0.000</td> <td>    0.606</td> <td>    0.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Device_Mobile</th>                                  <td>    2.6213</td> <td>    0.041</td> <td>   63.276</td> <td> 0.000</td> <td>    2.540</td> <td>    2.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Device_Tablet</th>                                  <td>    0.0527</td> <td>    0.060</td> <td>    0.883</td> <td> 0.377</td> <td>   -0.064</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Network (with search partners)_Search partners</th> <td>   -1.1820</td> <td>    0.118</td> <td>  -10.050</td> <td> 0.000</td> <td>   -1.413</td> <td>   -0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing page experience_Average</th>                <td>    0.8604</td> <td>    0.112</td> <td>    7.691</td> <td> 0.000</td> <td>    0.641</td> <td>    1.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing page experience_Below average</th>          <td>   -0.1859</td> <td>    0.819</td> <td>   -0.227</td> <td> 0.820</td> <td>   -1.791</td> <td>    1.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Expected click-through rate_Average</th>            <td>    0.0488</td> <td>    0.053</td> <td>    0.924</td> <td> 0.356</td> <td>   -0.055</td> <td>    0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Expected click-through rate_Below average</th>      <td>   -0.1678</td> <td>    0.183</td> <td>   -0.918</td> <td> 0.359</td> <td>   -0.526</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ad relevance_Average</th>                           <td>    0.4160</td> <td>    0.097</td> <td>    4.300</td> <td> 0.000</td> <td>    0.226</td> <td>    0.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ad relevance_Below average</th>                     <td>   -1.2632</td> <td>    0.040</td> <td>  -31.423</td> <td> 0.000</td> <td>   -1.342</td> <td>   -1.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 10</th>             <td>   -1.8473</td> <td>    0.364</td> <td>   -5.070</td> <td> 0.000</td> <td>   -2.561</td> <td>   -1.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 11</th>             <td>   -0.3747</td> <td>    0.645</td> <td>   -0.581</td> <td> 0.561</td> <td>   -1.640</td> <td>    0.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 12</th>             <td>   -0.4347</td> <td>    0.723</td> <td>   -0.601</td> <td> 0.548</td> <td>   -1.852</td> <td>    0.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 13</th>             <td>   -1.6083</td> <td>    0.771</td> <td>   -2.086</td> <td> 0.037</td> <td>   -3.120</td> <td>   -0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 14</th>             <td>   -1.9839</td> <td>    0.808</td> <td>   -2.455</td> <td> 0.014</td> <td>   -3.568</td> <td>   -0.400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 15</th>             <td>   -1.5762</td> <td>    0.985</td> <td>   -1.600</td> <td> 0.110</td> <td>   -3.506</td> <td>    0.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 16</th>             <td>   -1.9392</td> <td>    1.320</td> <td>   -1.469</td> <td> 0.142</td> <td>   -4.527</td> <td>    0.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 17</th>             <td>   -2.1405</td> <td>    1.418</td> <td>   -1.510</td> <td> 0.131</td> <td>   -4.919</td> <td>    0.638</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 18</th>             <td>   -2.9816</td> <td>    1.541</td> <td>   -1.935</td> <td> 0.053</td> <td>   -6.002</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 19</th>             <td>   -2.1155</td> <td>    2.286</td> <td>   -0.926</td> <td> 0.355</td> <td>   -6.596</td> <td>    2.364</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 2</th>              <td>   -1.6760</td> <td>    0.102</td> <td>  -16.395</td> <td> 0.000</td> <td>   -1.876</td> <td>   -1.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 20</th>             <td>   -3.1783</td> <td>    2.555</td> <td>   -1.244</td> <td> 0.214</td> <td>   -8.186</td> <td>    1.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 21</th>             <td>   -1.0827</td> <td>    3.062</td> <td>   -0.354</td> <td> 0.724</td> <td>   -7.084</td> <td>    4.919</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 22</th>             <td>   -0.0285</td> <td>    2.950</td> <td>   -0.010</td> <td> 0.992</td> <td>   -5.810</td> <td>    5.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 23</th>             <td>   -3.7778</td> <td>    3.614</td> <td>   -1.045</td> <td> 0.296</td> <td>  -10.862</td> <td>    3.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 24</th>             <td>   -4.0889</td> <td>    3.615</td> <td>   -1.131</td> <td> 0.258</td> <td>  -11.174</td> <td>    2.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 25</th>             <td>   -5.5515</td> <td>    5.110</td> <td>   -1.086</td> <td> 0.277</td> <td>  -15.567</td> <td>    4.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 26</th>             <td>    0.5432</td> <td>    5.109</td> <td>    0.106</td> <td> 0.915</td> <td>   -9.471</td> <td>   10.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 27</th>             <td>   -3.2649</td> <td>    5.110</td> <td>   -0.639</td> <td> 0.523</td> <td>  -13.281</td> <td>    6.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 28</th>             <td>    0.7998</td> <td>    5.110</td> <td>    0.157</td> <td> 0.876</td> <td>   -9.215</td> <td>   10.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 29</th>             <td>-1.043e-15</td> <td> 2.88e-15</td> <td>   -0.362</td> <td> 0.718</td> <td> -6.7e-15</td> <td> 4.61e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 3</th>              <td>   -0.0202</td> <td>    0.159</td> <td>   -0.127</td> <td> 0.899</td> <td>   -0.331</td> <td>    0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 30</th>             <td>   -3.4054</td> <td>    5.109</td> <td>   -0.667</td> <td> 0.505</td> <td>  -13.419</td> <td>    6.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 4</th>              <td>   -2.7190</td> <td>    0.180</td> <td>  -15.088</td> <td> 0.000</td> <td>   -3.072</td> <td>   -2.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 5</th>              <td>   -2.2234</td> <td>    0.210</td> <td>  -10.599</td> <td> 0.000</td> <td>   -2.635</td> <td>   -1.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 6</th>              <td>    0.8290</td> <td>    0.223</td> <td>    3.714</td> <td> 0.000</td> <td>    0.392</td> <td>    1.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 7</th>              <td>   -1.5234</td> <td>    0.256</td> <td>   -5.953</td> <td> 0.000</td> <td>   -2.025</td> <td>   -1.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 8</th>              <td>   -2.9795</td> <td>    0.274</td> <td>  -10.881</td> <td> 0.000</td> <td>   -3.516</td> <td>   -2.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 9</th>              <td>   -2.5043</td> <td>    0.327</td> <td>   -7.665</td> <td> 0.000</td> <td>   -3.145</td> <td>   -1.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Display URL_Insuro.co.uk/Black-Box-Insurance</th>   <td>   -1.8134</td> <td>    1.049</td> <td>   -1.728</td> <td> 0.084</td> <td>   -3.870</td> <td>    0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Display URL_Insuro.co.uk/Cheap-Car-Insurance</th>   <td>    0.7471</td> <td>    2.288</td> <td>    0.327</td> <td> 0.744</td> <td>   -3.736</td> <td>    5.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Display URL_Insuro.co.uk/Compare-Car-Insurance</th> <td>-1.188e-15</td> <td> 1.32e-15</td> <td>   -0.900</td> <td> 0.368</td> <td>-3.77e-15</td> <td>  1.4e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Display URL_Insuro.co.uk/Get-Car-Insurance</th>     <td>    0.9504</td> <td>    0.475</td> <td>    2.002</td> <td> 0.045</td> <td>    0.020</td> <td>    1.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Display URL_Insuro.co.uk/No-Deposit-Insurance</th>  <td>    0.4185</td> <td>    0.787</td> <td>    0.532</td> <td> 0.595</td> <td>   -1.124</td> <td>    1.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Display URL_Insuro.co.uk/NoDepositCarInsurance</th> <td>    0.3990</td> <td>    0.298</td> <td>    1.339</td> <td> 0.181</td> <td>   -0.185</td> <td>    0.983</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>120254.517</td> <th>  Durbin-Watson:     </th>   <td>   2.007</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>85071639.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 8.427</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>158.613</td>  <th>  Cond. No.          </th>   <td>3.61e+16</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.54e-28. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            Conversions   R-squared:                       0.233\n",
       "Model:                            OLS   Adj. R-squared:                  0.233\n",
       "Method:                 Least Squares   F-statistic:                     486.6\n",
       "Date:                Mon, 29 Jul 2019   Prob (F-statistic):               0.00\n",
       "Time:                        13:23:18   Log-Likelihood:            -2.5414e+05\n",
       "No. Observations:               83337   AIC:                         5.084e+05\n",
       "Df Residuals:                   83285   BIC:                         5.089e+05\n",
       "Df Model:                          52                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================================================\n",
       "                                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------\n",
       "No. of words                                       0.3190      0.012     25.889      0.000       0.295       0.343\n",
       "Avg. CPC_zscore                                    0.5073      0.018     28.249      0.000       0.472       0.542\n",
       "Search keyword match type_Exact                   -0.4565      0.044    -10.413      0.000      -0.542      -0.371\n",
       "Search keyword match type_Phrase                  -0.0184      0.056     -0.328      0.743      -0.129       0.092\n",
       "Day of week_Monday                                 0.7220      0.061     11.915      0.000       0.603       0.841\n",
       "Day of week_Saturday                               0.6054      0.061      9.922      0.000       0.486       0.725\n",
       "Day of week_Sunday                                 0.4988      0.061      8.162      0.000       0.379       0.619\n",
       "Day of week_Thursday                               0.7183      0.061     11.772      0.000       0.599       0.838\n",
       "Day of week_Tuesday                                0.7163      0.061     11.831      0.000       0.598       0.835\n",
       "Day of week_Wednesday                              0.7256      0.061     11.886      0.000       0.606       0.845\n",
       "Device_Mobile                                      2.6213      0.041     63.276      0.000       2.540       2.702\n",
       "Device_Tablet                                      0.0527      0.060      0.883      0.377      -0.064       0.170\n",
       "Network (with search partners)_Search partners    -1.1820      0.118    -10.050      0.000      -1.413      -0.951\n",
       "Landing page experience_Average                    0.8604      0.112      7.691      0.000       0.641       1.080\n",
       "Landing page experience_Below average             -0.1859      0.819     -0.227      0.820      -1.791       1.419\n",
       "Expected click-through rate_Average                0.0488      0.053      0.924      0.356      -0.055       0.152\n",
       "Expected click-through rate_Below average         -0.1678      0.183     -0.918      0.359      -0.526       0.191\n",
       "Ad relevance_Average                               0.4160      0.097      4.300      0.000       0.226       0.606\n",
       "Ad relevance_Below average                        -1.2632      0.040    -31.423      0.000      -1.342      -1.184\n",
       "Landing Page_Landing Page Group 10                -1.8473      0.364     -5.070      0.000      -2.561      -1.133\n",
       "Landing Page_Landing Page Group 11                -0.3747      0.645     -0.581      0.561      -1.640       0.890\n",
       "Landing Page_Landing Page Group 12                -0.4347      0.723     -0.601      0.548      -1.852       0.983\n",
       "Landing Page_Landing Page Group 13                -1.6083      0.771     -2.086      0.037      -3.120      -0.097\n",
       "Landing Page_Landing Page Group 14                -1.9839      0.808     -2.455      0.014      -3.568      -0.400\n",
       "Landing Page_Landing Page Group 15                -1.5762      0.985     -1.600      0.110      -3.506       0.354\n",
       "Landing Page_Landing Page Group 16                -1.9392      1.320     -1.469      0.142      -4.527       0.649\n",
       "Landing Page_Landing Page Group 17                -2.1405      1.418     -1.510      0.131      -4.919       0.638\n",
       "Landing Page_Landing Page Group 18                -2.9816      1.541     -1.935      0.053      -6.002       0.039\n",
       "Landing Page_Landing Page Group 19                -2.1155      2.286     -0.926      0.355      -6.596       2.364\n",
       "Landing Page_Landing Page Group 2                 -1.6760      0.102    -16.395      0.000      -1.876      -1.476\n",
       "Landing Page_Landing Page Group 20                -3.1783      2.555     -1.244      0.214      -8.186       1.830\n",
       "Landing Page_Landing Page Group 21                -1.0827      3.062     -0.354      0.724      -7.084       4.919\n",
       "Landing Page_Landing Page Group 22                -0.0285      2.950     -0.010      0.992      -5.810       5.753\n",
       "Landing Page_Landing Page Group 23                -3.7778      3.614     -1.045      0.296     -10.862       3.306\n",
       "Landing Page_Landing Page Group 24                -4.0889      3.615     -1.131      0.258     -11.174       2.996\n",
       "Landing Page_Landing Page Group 25                -5.5515      5.110     -1.086      0.277     -15.567       4.464\n",
       "Landing Page_Landing Page Group 26                 0.5432      5.109      0.106      0.915      -9.471      10.557\n",
       "Landing Page_Landing Page Group 27                -3.2649      5.110     -0.639      0.523     -13.281       6.751\n",
       "Landing Page_Landing Page Group 28                 0.7998      5.110      0.157      0.876      -9.215      10.815\n",
       "Landing Page_Landing Page Group 29             -1.043e-15   2.88e-15     -0.362      0.718    -6.7e-15    4.61e-15\n",
       "Landing Page_Landing Page Group 3                 -0.0202      0.159     -0.127      0.899      -0.331       0.291\n",
       "Landing Page_Landing Page Group 30                -3.4054      5.109     -0.667      0.505     -13.419       6.608\n",
       "Landing Page_Landing Page Group 4                 -2.7190      0.180    -15.088      0.000      -3.072      -2.366\n",
       "Landing Page_Landing Page Group 5                 -2.2234      0.210    -10.599      0.000      -2.635      -1.812\n",
       "Landing Page_Landing Page Group 6                  0.8290      0.223      3.714      0.000       0.392       1.266\n",
       "Landing Page_Landing Page Group 7                 -1.5234      0.256     -5.953      0.000      -2.025      -1.022\n",
       "Landing Page_Landing Page Group 8                 -2.9795      0.274    -10.881      0.000      -3.516      -2.443\n",
       "Landing Page_Landing Page Group 9                 -2.5043      0.327     -7.665      0.000      -3.145      -1.864\n",
       "Display URL_Insuro.co.uk/Black-Box-Insurance      -1.8134      1.049     -1.728      0.084      -3.870       0.243\n",
       "Display URL_Insuro.co.uk/Cheap-Car-Insurance       0.7471      2.288      0.327      0.744      -3.736       5.231\n",
       "Display URL_Insuro.co.uk/Compare-Car-Insurance -1.188e-15   1.32e-15     -0.900      0.368   -3.77e-15     1.4e-15\n",
       "Display URL_Insuro.co.uk/Get-Car-Insurance         0.9504      0.475      2.002      0.045       0.020       1.881\n",
       "Display URL_Insuro.co.uk/No-Deposit-Insurance      0.4185      0.787      0.532      0.595      -1.124       1.961\n",
       "Display URL_Insuro.co.uk/NoDepositCarInsurance     0.3990      0.298      1.339      0.181      -0.185       0.983\n",
       "==============================================================================\n",
       "Omnibus:                   120254.517   Durbin-Watson:                   2.007\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         85071639.859\n",
       "Skew:                           8.427   Prob(JB):                         0.00\n",
       "Kurtosis:                     158.613   Cond. No.                     3.61e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.54e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary of OLS\n",
    "from statsmodels.api import OLS\n",
    "OLS(y,X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.87651772484952\n",
      "26.25758569996043\n"
     ]
    }
   ],
   "source": [
    "# Base models\n",
    "    \n",
    "#Random forest\n",
    "# rf_base = RandomForestRegressor(n_estimators=200,max_depth=4,max_features='sqrt',random_state=42)\n",
    "# rf_base.fit(X,y)\n",
    "# print(mean_squared_error(rf.predict(X_val),y_val))\n",
    "\n",
    "#OLS with kfold\n",
    "# baseline model\n",
    "lm_base = linear_model.LinearRegression()\n",
    "fold_mse_conv_lm_base = []\n",
    "fold_max_conv_lm_base=[]\n",
    "fold_min_conv_lm_base=[]\n",
    "fold_r2_base=[]\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index], \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    lm_base.fit(X_train, y_train)\n",
    "    y_pred_base=lm_base.predict(X_test)\n",
    "    fold_mse_conv_lm_base.append(mean_squared_error(y_pred_base,y_test))\n",
    "#     fold_max_conv_lm.append(y_pred.max())\n",
    "#     fold_min_conv_lm.append(y_pred.min())\n",
    "print(np.mean(fold_mse_conv_lm_base))\n",
    "\n",
    "rf_base =RandomForestRegressor(n_estimators=200,max_depth=4,max_features='sqrt',random_state=42)\n",
    "fold_mse_conv_rf_base = []\n",
    "fold_max_conv_rf_base=[]\n",
    "fold_min_conv_rf_base=[]\n",
    "fold_r2=[]\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index], \n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    rf_base.fit(X_train, y_train)\n",
    "    y_pred_rf_base=rf_base.predict(X_test)\n",
    "    fold_mse_conv_rf_base.append(mean_squared_error(y_pred_rf_base,y_test))\n",
    "#     fold_max_conv_rf_base.append(y_pred.max())\n",
    "#     fold_min_conv_lm.append(y_pred.min())\n",
    "\n",
    "print(np.mean(fold_mse_conv_rf_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset for classification of 0 or more than 0\n",
    "y_conv_bin=pd.DataFrame(y).apply(conv_binary,axis=1)\n",
    "\n",
    "#dataset for regressor\n",
    "#get dataset with more than 0\n",
    "X_train_regr=X[X.index.isin(y[y>0].index)]\n",
    "y_train_regr=y[y>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 model construction (Classification)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#split for logreg\n",
    "X, X_val, y, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf_conv = LogisticRegression()\n",
    "clf_conv.fit(X_conv_class_train,y_conv_class_train)\n",
    "y_conv_class_pred=clf_conv.predict(X_conv_class_test)\n",
    "print(accuracy_score(y_conv_class_test, y_conv_class_pred))\n",
    "print(confusion_matrix(y_conv_class_test, y_conv_class_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_conv_test, y_conv_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# ROC curve\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7023380093520374, 0.7045697487974345, 0.6998931052912881, 0.6992250133618386, 0.7008284339925174, 0.6874665954035275, 0.6968198824158204, 0.7111170497060395, 0.7014965259219669, 0.6942811330839124]\n",
      "[[ 1695 21252]\n",
      " [ 1215 50679]]\n",
      "[0.5224030430601807, 0.5288659511671994, 0.5277934902910895, 0.5293094828537961, 0.518949599270659, 0.5223643144563636, 0.5254018156229456, 0.5271618700757108, 0.5278848372376338, 0.5222260435421837]\n"
     ]
    }
   ],
   "source": [
    "#L1 Log Reg\n",
    "clf_conv_lr1 = LogisticRegression(penalty='l1')\n",
    "logregl1_misclass = []\n",
    "logregl1_confmat=0\n",
    "logregl1_rocauc=[]\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index], \n",
    "    y_train, y_test = y_conv_bin.iloc[train_index], y_conv_bin.iloc[test_index]\n",
    "    clf_conv_lr1.fit(X_train, y_train)\n",
    "    y_conv_pred=clf_conv_lr1.predict(X_test)\n",
    "    logregl1_misclass.append(accuracy_score(y_test, y_conv_pred))\n",
    "    logregl1_confmat=logregl1_confmat+confusion_matrix(y_test, y_conv_pred)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_conv_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    logregl1_rocauc.append(roc_auc)\n",
    "print(logregl1_misclass)\n",
    "print(logregl1_confmat)\n",
    "print(logregl1_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7022044088176352, 0.7045697487974345, 0.700026723677178, 0.6993586317477285, 0.7008284339925174, 0.6871993586317477, 0.6966862640299305, 0.7112506680919295, 0.7016301443078568, 0.6942811330839124]\n",
      "[[ 1700 21247]\n",
      " [ 1220 50674]]\n",
      "[0.5223074955730795, 0.5288659511671994, 0.5282498854513843, 0.5295249072398366, 0.5190769958226177, 0.5220566124076615, 0.5253051225268327, 0.5273874000712002, 0.527981343703567, 0.5222260435421837]\n"
     ]
    }
   ],
   "source": [
    "#L2 Log Reg\n",
    "clf_conv_lr2 = LogisticRegression(penalty='l2')\n",
    "logregl2_misclass = []\n",
    "logregl2_confmat=0\n",
    "logregl2_rocauc=[]\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index], \n",
    "    y_train, y_test = y_conv_bin.iloc[train_index], y_conv_bin.iloc[test_index]\n",
    "    clf_conv_lr2.fit(X_train, y_train)\n",
    "    y_conv_pred=clf_conv_lr2.predict(X_test)\n",
    "    logregl2_misclass.append(accuracy_score(y_test, y_conv_pred))\n",
    "    logregl2_confmat=logregl2_confmat+confusion_matrix(y_test, y_conv_pred)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_conv_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    logregl2_rocauc.append(roc_auc)\n",
    "print(logregl2_misclass)\n",
    "print(logregl2_confmat)\n",
    "print(logregl2_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6952571810287241, 0.6969535008017104, 0.6941475146980225, 0.6961517904863709, 0.6830571886691609, 0.6783805451630144, 0.6962854088722609, 0.71058257616248, 0.6997594869053981, 0.6917423837520043]\n",
      "[[ 1999 20948]\n",
      " [ 1936 49958]]\n",
      "[0.5275836939982261, 0.5130858285982365, 0.515004257651743, 0.5229317443917685, 0.5420571906764093, 0.5274127824627923, 0.5198775588659459, 0.5262597500937531, 0.5411024516497577, 0.5149836064263874]\n"
     ]
    }
   ],
   "source": [
    "#### SGD Classifier\n",
    "clf_conv_sgd = linear_model.SGDClassifier()\n",
    "sgdclass_misclass = []\n",
    "sgdclass_confmat=0\n",
    "sgdclass_rocauc=[]\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index], \n",
    "    y_train, y_test = y_conv_bin.iloc[train_index], y_conv_bin.iloc[test_index]\n",
    "    clf_conv_sgd.fit(X_train, y_train)\n",
    "    y_conv_pred=clf_conv_sgd.predict(X_test)\n",
    "    sgdclass_misclass.append(accuracy_score(y_test, y_conv_pred))\n",
    "    sgdclass_confmat=sgdclass_confmat+confusion_matrix(y_test, y_conv_pred)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_conv_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    sgdclass_rocauc.append(roc_auc)\n",
    "print(sgdclass_misclass)\n",
    "print(sgdclass_confmat)\n",
    "print(sgdclass_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7150168518287355, 0.7198851579078767, 0.7047809262264386, 0.7146423667457247, 0.7133940831356884, 0.709274747222569, 0.7203844713518911, 0.7064036949194857, 0.7107726875546124, 0.718137560853826]\n",
      "[[  123 22940]\n",
      " [   30 57017]]\n",
      "[0.5033077949065063, 0.5016537875833279, 0.5024525430728601, 0.5023519578113493, 0.5022537198469715, 0.5018374243163984, 0.5031552233932388, 0.5020292511422714, 0.5022289040427536, 0.5027763432823795]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_conv_sgd = linear_model.SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
    "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
    "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
    "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "sgdclass_misclass = []\n",
    "sgdclass_confmat=0\n",
    "sgdclass_rocauc=[]\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index], \n",
    "    y_train, y_test = y_conv_bin.iloc[train_index], y_conv_bin.iloc[test_index]\n",
    "    clf_conv_sgd.fit(X_train, y_train)\n",
    "    y_conv_pred=clf_conv_sgd.predict(X_test)\n",
    "    sgdclass_misclass.append(accuracy_score(y_test, y_conv_pred))\n",
    "    sgdclass_confmat=sgdclass_confmat+confusion_matrix(y_test, y_conv_pred)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_conv_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    sgdclass_rocauc.append(roc_auc)\n",
    "print(sgdclass_misclass)\n",
    "print(sgdclass_confmat)\n",
    "print(sgdclass_rocauc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7211423086153108, 0.7297816174706023, 0.7215022798176146, 0.7236621070314375, 0.7335013198944085, 0.7243820494360451, 0.7212622990160787, 0.7245889835593424, 0.7321492859714389, 0.7238689547581904]\n",
      "[[   30 22869]\n",
      " [    0 60438]]\n",
      "[0.5, 0.5004436557231589, 0.5, 0.5, 0.5002250225022502, 0.5015190972222222, 0.5012881064834693, 0.5010869565217391, 0.5004476275738585, 0.5015164644714039]\n"
     ]
    }
   ],
   "source": [
    "#Random forest classifier conversions\n",
    "\n",
    "rf_conv = RandomForestClassifier(n_estimators=200, max_depth=4,random_state=0)\n",
    "rf_misclass = []\n",
    "rf_confmat=0\n",
    "rf_rocauc=[]\n",
    "for train_index, test_index in cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index], \n",
    "    y_train, y_test = y_conv_bin.iloc[train_index], y_conv_bin.iloc[test_index]\n",
    "    rf_conv.fit(X_train, y_train)\n",
    "    y_conv_pred=rf_conv.predict(X_test)\n",
    "    rf_misclass.append(accuracy_score(y_test, y_conv_pred))\n",
    "    rf_confmat=rf_confmat+confusion_matrix(y_test, y_conv_pred)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, y_conv_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    rf_rocauc.append(roc_auc)\n",
    "print(rf_misclass)\n",
    "print(rf_confmat)\n",
    "print(rf_rocauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Acc</th>\n",
       "      <th>False Negative Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logregl1</th>\n",
       "      <td>0.730024</td>\n",
       "      <td>0.019855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logregl2</th>\n",
       "      <td>0.729964</td>\n",
       "      <td>0.019921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.725788</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.728056</td>\n",
       "      <td>0.022238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Classification Acc  False Negative Rate\n",
       "logregl1            0.730024             0.019855\n",
       "logregl2            0.729964             0.019921\n",
       "rf                  0.725788             0.000066\n",
       "sgd                 0.728056             0.022238"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclass={'logregl1':np.mean(logregl1_misclass),'logregl2':np.mean(logregl2_misclass), 'sgd':np.mean(sgdclass_misclass),'rf':np.mean(rf_misclass)}\n",
    "false_negative_rate={'logregl1':(logregl1_confmat[1][0]/np.sum(logregl1_confmat[1])),'logregl2':(logregl2_confmat[1][0]/np.sum(logregl2_confmat[1])), 'sgd':(sgdclass_confmat[1][0]/np.sum(sgdclass_confmat[1])),'rf':(rf_confmat[1][0]/np.sum(rf_confmat[1]))}\n",
    "classification_results=pd.DataFrame([misclass, false_negative_rate],index=['Classification Acc','False Negative Rate']).T\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 (Continuous prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/statsmodels/base/model.py:1100: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1831: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>Conversions</td>   <th>  R-squared:         </th>  <td>   0.301</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.301</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   543.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 29 Jul 2019</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:34:18</td>     <th>  Log-Likelihood:    </th> <td>-1.9119e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 60438</td>      <th>  AIC:               </th>  <td>3.825e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 60390</td>      <th>  BIC:               </th>  <td>3.829e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    48</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                         <td></td>                           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. of words</th>                                   <td>    0.4102</td> <td>    0.016</td> <td>   25.387</td> <td> 0.000</td> <td>    0.379</td> <td>    0.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Avg. CPC_zscore</th>                                <td>    0.5755</td> <td>    0.025</td> <td>   23.267</td> <td> 0.000</td> <td>    0.527</td> <td>    0.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Search keyword match type_Exact</th>                <td>   -0.7223</td> <td>    0.057</td> <td>  -12.572</td> <td> 0.000</td> <td>   -0.835</td> <td>   -0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Search keyword match type_Phrase</th>               <td>   -0.1829</td> <td>    0.073</td> <td>   -2.497</td> <td> 0.013</td> <td>   -0.327</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Day of week_Monday</th>                             <td>    1.0158</td> <td>    0.080</td> <td>   12.730</td> <td> 0.000</td> <td>    0.859</td> <td>    1.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Day of week_Saturday</th>                           <td>    0.8171</td> <td>    0.080</td> <td>   10.183</td> <td> 0.000</td> <td>    0.660</td> <td>    0.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Day of week_Sunday</th>                             <td>    0.7114</td> <td>    0.080</td> <td>    8.851</td> <td> 0.000</td> <td>    0.554</td> <td>    0.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Day of week_Thursday</th>                           <td>    0.9565</td> <td>    0.080</td> <td>   11.960</td> <td> 0.000</td> <td>    0.800</td> <td>    1.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Day of week_Tuesday</th>                            <td>    0.9759</td> <td>    0.080</td> <td>   12.247</td> <td> 0.000</td> <td>    0.820</td> <td>    1.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Day of week_Wednesday</th>                          <td>    0.9500</td> <td>    0.080</td> <td>   11.860</td> <td> 0.000</td> <td>    0.793</td> <td>    1.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Device_Mobile</th>                                  <td>    3.3252</td> <td>    0.055</td> <td>   61.009</td> <td> 0.000</td> <td>    3.218</td> <td>    3.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Device_Tablet</th>                                  <td>    0.1856</td> <td>    0.083</td> <td>    2.235</td> <td> 0.025</td> <td>    0.023</td> <td>    0.348</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Network (with search partners)_Search partners</th> <td>   -0.8939</td> <td>    0.201</td> <td>   -4.444</td> <td> 0.000</td> <td>   -1.288</td> <td>   -0.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing page experience_Average</th>                <td>    1.1087</td> <td>    0.154</td> <td>    7.200</td> <td> 0.000</td> <td>    0.807</td> <td>    1.411</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing page experience_Below average</th>          <td>    3.6146</td> <td>    1.811</td> <td>    1.995</td> <td> 0.046</td> <td>    0.064</td> <td>    7.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Expected click-through rate_Average</th>            <td>    0.0978</td> <td>    0.071</td> <td>    1.368</td> <td> 0.171</td> <td>   -0.042</td> <td>    0.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Expected click-through rate_Below average</th>      <td>   -0.1215</td> <td>    0.251</td> <td>   -0.485</td> <td> 0.628</td> <td>   -0.613</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ad relevance_Average</th>                           <td>    0.6264</td> <td>    0.132</td> <td>    4.754</td> <td> 0.000</td> <td>    0.368</td> <td>    0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ad relevance_Below average</th>                     <td>   -1.4898</td> <td>    0.054</td> <td>  -27.815</td> <td> 0.000</td> <td>   -1.595</td> <td>   -1.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 10</th>             <td>   -2.2500</td> <td>    0.654</td> <td>   -3.439</td> <td> 0.001</td> <td>   -3.532</td> <td>   -0.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 11</th>             <td>   -0.2091</td> <td>    0.984</td> <td>   -0.213</td> <td> 0.832</td> <td>   -2.138</td> <td>    1.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 12</th>             <td>   -0.2476</td> <td>    1.064</td> <td>   -0.233</td> <td> 0.816</td> <td>   -2.333</td> <td>    1.838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 13</th>             <td>   -2.1657</td> <td>    1.013</td> <td>   -2.137</td> <td> 0.033</td> <td>   -4.152</td> <td>   -0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 14</th>             <td>   -2.1508</td> <td>    1.389</td> <td>   -1.548</td> <td> 0.122</td> <td>   -4.874</td> <td>    0.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 15</th>             <td>   -1.9041</td> <td>    1.590</td> <td>   -1.197</td> <td> 0.231</td> <td>   -5.021</td> <td>    1.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 16</th>             <td>   -2.7989</td> <td>    2.165</td> <td>   -1.293</td> <td> 0.196</td> <td>   -7.043</td> <td>    1.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 17</th>             <td>   -2.2528</td> <td>    2.863</td> <td>   -0.787</td> <td> 0.431</td> <td>   -7.864</td> <td>    3.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 18</th>             <td>   -3.5059</td> <td>    2.338</td> <td>   -1.499</td> <td> 0.134</td> <td>   -8.089</td> <td>    1.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 19</th>             <td>   -2.0632</td> <td>    4.050</td> <td>   -0.509</td> <td> 0.610</td> <td>  -10.001</td> <td>    5.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 2</th>              <td>   -1.8631</td> <td>    0.149</td> <td>  -12.467</td> <td> 0.000</td> <td>   -2.156</td> <td>   -1.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 20</th>             <td>   -3.4638</td> <td>    5.726</td> <td>   -0.605</td> <td> 0.545</td> <td>  -14.686</td> <td>    7.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 21</th>             <td>   -3.9734</td> <td>    6.006</td> <td>   -0.662</td> <td> 0.508</td> <td>  -15.745</td> <td>    7.799</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 22</th>             <td>   -0.8099</td> <td>    3.306</td> <td>   -0.245</td> <td> 0.806</td> <td>   -7.290</td> <td>    5.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 23</th>             <td>   -4.6269</td> <td>    5.728</td> <td>   -0.808</td> <td> 0.419</td> <td>  -15.853</td> <td>    6.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 24</th>             <td>-5.361e-16</td> <td> 2.92e-15</td> <td>   -0.184</td> <td> 0.854</td> <td>-6.25e-15</td> <td> 5.18e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 25</th>             <td> 7.821e-17</td> <td> 2.59e-15</td> <td>    0.030</td> <td> 0.976</td> <td>   -5e-15</td> <td> 5.16e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 26</th>             <td>    0.3926</td> <td>    5.726</td> <td>    0.069</td> <td> 0.945</td> <td>  -10.831</td> <td>   11.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 27</th>             <td>   -4.8095</td> <td>    5.728</td> <td>   -0.840</td> <td> 0.401</td> <td>  -16.037</td> <td>    6.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 28</th>             <td> 1.913e-15</td> <td> 2.18e-15</td> <td>    0.877</td> <td> 0.381</td> <td>-2.36e-15</td> <td> 6.19e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 29</th>             <td> 7.967e-16</td> <td>  2.5e-15</td> <td>    0.318</td> <td> 0.750</td> <td>-4.11e-15</td> <td>  5.7e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 3</th>              <td>    0.3340</td> <td>    0.205</td> <td>    1.626</td> <td> 0.104</td> <td>   -0.069</td> <td>    0.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 30</th>             <td> 2.184e-15</td> <td>  2.2e-15</td> <td>    0.992</td> <td> 0.321</td> <td>-2.13e-15</td> <td>  6.5e-15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 4</th>              <td>   -3.3246</td> <td>    0.253</td> <td>  -13.148</td> <td> 0.000</td> <td>   -3.820</td> <td>   -2.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 5</th>              <td>   -2.4704</td> <td>    0.289</td> <td>   -8.562</td> <td> 0.000</td> <td>   -3.036</td> <td>   -1.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 6</th>              <td>    0.5405</td> <td>    0.263</td> <td>    2.054</td> <td> 0.040</td> <td>    0.025</td> <td>    1.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 7</th>              <td>   -1.4106</td> <td>    0.427</td> <td>   -3.307</td> <td> 0.001</td> <td>   -2.247</td> <td>   -0.574</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 8</th>              <td>   -3.2646</td> <td>    0.428</td> <td>   -7.632</td> <td> 0.000</td> <td>   -4.103</td> <td>   -2.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Landing Page_Landing Page Group 9</th>              <td>   -3.3210</td> <td>    0.465</td> <td>   -7.136</td> <td> 0.000</td> <td>   -4.233</td> <td>   -2.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Display URL_Insuro.co.uk/Black-Box-Insurance</th>   <td>   -1.9965</td> <td>    1.441</td> <td>   -1.386</td> <td> 0.166</td> <td>   -4.821</td> <td>    0.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Display URL_Insuro.co.uk/Cheap-Car-Insurance</th>   <td>   -0.0181</td> <td>    3.310</td> <td>   -0.005</td> <td> 0.996</td> <td>   -6.505</td> <td>    6.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Display URL_Insuro.co.uk/Compare-Car-Insurance</th> <td>         0</td> <td>        0</td> <td>      nan</td> <td>   nan</td> <td>        0</td> <td>        0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Display URL_Insuro.co.uk/Get-Car-Insurance</th>     <td>    0.9851</td> <td>    0.640</td> <td>    1.539</td> <td> 0.124</td> <td>   -0.270</td> <td>    2.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Display URL_Insuro.co.uk/No-Deposit-Insurance</th>  <td>    0.7696</td> <td>    1.260</td> <td>    0.611</td> <td> 0.541</td> <td>   -1.700</td> <td>    3.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Display URL_Insuro.co.uk/NoDepositCarInsurance</th> <td>    0.6904</td> <td>    0.438</td> <td>    1.577</td> <td> 0.115</td> <td>   -0.168</td> <td>    1.549</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>82645.412</td> <th>  Durbin-Watson:     </th>   <td>   2.009</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>42085160.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 7.674</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>131.361</td>  <th>  Cond. No.          </th>   <td>1.03e+16</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 6.65e-27. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            Conversions   R-squared:                       0.301\n",
       "Model:                            OLS   Adj. R-squared:                  0.301\n",
       "Method:                 Least Squares   F-statistic:                     543.0\n",
       "Date:                Mon, 29 Jul 2019   Prob (F-statistic):               0.00\n",
       "Time:                        13:34:18   Log-Likelihood:            -1.9119e+05\n",
       "No. Observations:               60438   AIC:                         3.825e+05\n",
       "Df Residuals:                   60390   BIC:                         3.829e+05\n",
       "Df Model:                          48                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================================================\n",
       "                                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------\n",
       "No. of words                                       0.4102      0.016     25.387      0.000       0.379       0.442\n",
       "Avg. CPC_zscore                                    0.5755      0.025     23.267      0.000       0.527       0.624\n",
       "Search keyword match type_Exact                   -0.7223      0.057    -12.572      0.000      -0.835      -0.610\n",
       "Search keyword match type_Phrase                  -0.1829      0.073     -2.497      0.013      -0.327      -0.039\n",
       "Day of week_Monday                                 1.0158      0.080     12.730      0.000       0.859       1.172\n",
       "Day of week_Saturday                               0.8171      0.080     10.183      0.000       0.660       0.974\n",
       "Day of week_Sunday                                 0.7114      0.080      8.851      0.000       0.554       0.869\n",
       "Day of week_Thursday                               0.9565      0.080     11.960      0.000       0.800       1.113\n",
       "Day of week_Tuesday                                0.9759      0.080     12.247      0.000       0.820       1.132\n",
       "Day of week_Wednesday                              0.9500      0.080     11.860      0.000       0.793       1.107\n",
       "Device_Mobile                                      3.3252      0.055     61.009      0.000       3.218       3.432\n",
       "Device_Tablet                                      0.1856      0.083      2.235      0.025       0.023       0.348\n",
       "Network (with search partners)_Search partners    -0.8939      0.201     -4.444      0.000      -1.288      -0.500\n",
       "Landing page experience_Average                    1.1087      0.154      7.200      0.000       0.807       1.411\n",
       "Landing page experience_Below average              3.6146      1.811      1.995      0.046       0.064       7.165\n",
       "Expected click-through rate_Average                0.0978      0.071      1.368      0.171      -0.042       0.238\n",
       "Expected click-through rate_Below average         -0.1215      0.251     -0.485      0.628      -0.613       0.370\n",
       "Ad relevance_Average                               0.6264      0.132      4.754      0.000       0.368       0.885\n",
       "Ad relevance_Below average                        -1.4898      0.054    -27.815      0.000      -1.595      -1.385\n",
       "Landing Page_Landing Page Group 10                -2.2500      0.654     -3.439      0.001      -3.532      -0.968\n",
       "Landing Page_Landing Page Group 11                -0.2091      0.984     -0.213      0.832      -2.138       1.719\n",
       "Landing Page_Landing Page Group 12                -0.2476      1.064     -0.233      0.816      -2.333       1.838\n",
       "Landing Page_Landing Page Group 13                -2.1657      1.013     -2.137      0.033      -4.152      -0.180\n",
       "Landing Page_Landing Page Group 14                -2.1508      1.389     -1.548      0.122      -4.874       0.572\n",
       "Landing Page_Landing Page Group 15                -1.9041      1.590     -1.197      0.231      -5.021       1.213\n",
       "Landing Page_Landing Page Group 16                -2.7989      2.165     -1.293      0.196      -7.043       1.445\n",
       "Landing Page_Landing Page Group 17                -2.2528      2.863     -0.787      0.431      -7.864       3.359\n",
       "Landing Page_Landing Page Group 18                -3.5059      2.338     -1.499      0.134      -8.089       1.077\n",
       "Landing Page_Landing Page Group 19                -2.0632      4.050     -0.509      0.610     -10.001       5.875\n",
       "Landing Page_Landing Page Group 2                 -1.8631      0.149    -12.467      0.000      -2.156      -1.570\n",
       "Landing Page_Landing Page Group 20                -3.4638      5.726     -0.605      0.545     -14.686       7.758\n",
       "Landing Page_Landing Page Group 21                -3.9734      6.006     -0.662      0.508     -15.745       7.799\n",
       "Landing Page_Landing Page Group 22                -0.8099      3.306     -0.245      0.806      -7.290       5.671\n",
       "Landing Page_Landing Page Group 23                -4.6269      5.728     -0.808      0.419     -15.853       6.600\n",
       "Landing Page_Landing Page Group 24             -5.361e-16   2.92e-15     -0.184      0.854   -6.25e-15    5.18e-15\n",
       "Landing Page_Landing Page Group 25              7.821e-17   2.59e-15      0.030      0.976      -5e-15    5.16e-15\n",
       "Landing Page_Landing Page Group 26                 0.3926      5.726      0.069      0.945     -10.831      11.616\n",
       "Landing Page_Landing Page Group 27                -4.8095      5.728     -0.840      0.401     -16.037       6.417\n",
       "Landing Page_Landing Page Group 28              1.913e-15   2.18e-15      0.877      0.381   -2.36e-15    6.19e-15\n",
       "Landing Page_Landing Page Group 29              7.967e-16    2.5e-15      0.318      0.750   -4.11e-15     5.7e-15\n",
       "Landing Page_Landing Page Group 3                  0.3340      0.205      1.626      0.104      -0.069       0.737\n",
       "Landing Page_Landing Page Group 30              2.184e-15    2.2e-15      0.992      0.321   -2.13e-15     6.5e-15\n",
       "Landing Page_Landing Page Group 4                 -3.3246      0.253    -13.148      0.000      -3.820      -2.829\n",
       "Landing Page_Landing Page Group 5                 -2.4704      0.289     -8.562      0.000      -3.036      -1.905\n",
       "Landing Page_Landing Page Group 6                  0.5405      0.263      2.054      0.040       0.025       1.056\n",
       "Landing Page_Landing Page Group 7                 -1.4106      0.427     -3.307      0.001      -2.247      -0.574\n",
       "Landing Page_Landing Page Group 8                 -3.2646      0.428     -7.632      0.000      -4.103      -2.426\n",
       "Landing Page_Landing Page Group 9                 -3.3210      0.465     -7.136      0.000      -4.233      -2.409\n",
       "Display URL_Insuro.co.uk/Black-Box-Insurance      -1.9965      1.441     -1.386      0.166      -4.821       0.828\n",
       "Display URL_Insuro.co.uk/Cheap-Car-Insurance      -0.0181      3.310     -0.005      0.996      -6.505       6.469\n",
       "Display URL_Insuro.co.uk/Compare-Car-Insurance          0          0        nan        nan           0           0\n",
       "Display URL_Insuro.co.uk/Get-Car-Insurance         0.9851      0.640      1.539      0.124      -0.270       2.240\n",
       "Display URL_Insuro.co.uk/No-Deposit-Insurance      0.7696      1.260      0.611      0.541      -1.700       3.239\n",
       "Display URL_Insuro.co.uk/NoDepositCarInsurance     0.6904      0.438      1.577      0.115      -0.168       1.549\n",
       "==============================================================================\n",
       "Omnibus:                    82645.412   Durbin-Watson:                   2.009\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         42085160.458\n",
       "Skew:                           7.674   Prob(JB):                         0.00\n",
       "Kurtosis:                     131.361   Cond. No.                     1.03e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 6.65e-27. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.api import OLS\n",
    "OLS(y_train_regr,X_train_regr).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8749750884785552\n"
     ]
    }
   ],
   "source": [
    "#split for transformation test\n",
    "\n",
    "y_train_regr_tran=np.cbrt(y_train_regr)\n",
    "\n",
    "#ols for transformation\n",
    "lm_tran = linear_model.LinearRegression()\n",
    "lm_mse_tran = []\n",
    "lm_r2=[]\n",
    "for train_index, test_index in cv.split(X_train_regr):\n",
    "    X_train, X_test = X_train_regr.iloc[train_index], X_train_regr.iloc[test_index], \n",
    "    y_train, y_test =y_train_regr_tran.iloc[train_index], y_train_regr_tran.iloc[test_index]\n",
    "    lm_tran.fit(X_train, y_train)\n",
    "    y_pred=lm.predict(X_test)\n",
    "    lm_mse_tran.append(mean_squared_error(y_pred**3,y_test**3)**0.5)\n",
    "\n",
    "print(np.mean(lm_mse_tran))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of y dependent variable\n",
    "y_train_regr=np.cbrt(y_train_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.904449387898964\n",
      "[0.039999073678476216, 0.04214725941642472, 0.04128563911703742, 0.052489009854309265, 0.04296756503603072, 0.04919252069247293, 0.043004378949440314, 0.03619449552255927, 0.03120130882520744, 0.049168325944984326]\n"
     ]
    }
   ],
   "source": [
    "#OLS without penalizer\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "lm_mse = []\n",
    "# fold_max_conv_lm=[]\n",
    "# fold_min_conv_lm=[]\n",
    "lm_r2=[]\n",
    "for train_index, test_index in cv.split(X_train_regr):\n",
    "    X_train, X_test = X_train_regr.iloc[train_index], X_train_regr.iloc[test_index], \n",
    "    y_train, y_test =y_train_regr.iloc[train_index], y_train_regr.iloc[test_index]\n",
    "    lm.fit(X_train, y_train)\n",
    "    y_pred=lm.predict(X_test)\n",
    "    lm_mse.append(mean_squared_error(y_pred**3,y_test**3))\n",
    "    lm_r2.append(r2_score(y_true=y_test**3, y_pred=y_pred**3))\n",
    "print(np.mean(lm_mse))\n",
    "print(lm_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.583994699672445\n",
      "[-0.02993454083044278, -0.028372468931280093, -0.03836193897364604, -0.03572102181388015, -0.0388996297931723, -0.03267864348461269, -0.0319089853393677, -0.03521688870175432, -0.03174360230994755, -0.034205066358256486]\n"
     ]
    }
   ],
   "source": [
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "lasso_mse = []\n",
    "# fold_max_conv_lm=[]\n",
    "# fold_min_conv_lm=[]\n",
    "lasso_r2=[]\n",
    "for train_index, test_index in cv.split(X_train_regr):\n",
    "    X_train, X_test = X_train_regr.iloc[train_index], X_train_regr.iloc[test_index], \n",
    "    y_train, y_test =y_train_regr.iloc[train_index], y_train_regr.iloc[test_index]\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred=lasso.predict(X_test)\n",
    "    lasso_mse.append(mean_squared_error(y_pred**3,y_test**3))\n",
    "    lasso_r2.append(r2_score(y_true=y_test**3, y_pred=y_pred**3))\n",
    "print(np.mean(lasso_mse))\n",
    "print(lasso_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.906240278732355\n",
      "[0.039953009059374045, 0.042149079755508856, 0.04123505249989401, 0.052430658228635685, 0.04288768660550135, 0.04913045199767463, 0.04295768330205707, 0.03614599713038458, 0.031135754722783626, 0.04911161015907939]\n"
     ]
    }
   ],
   "source": [
    "ridge = linear_model.Ridge(alpha=1)\n",
    "ridge_mse = []\n",
    "# fold_max_conv_lm=[]\n",
    "# fold_min_conv_lm=[]\n",
    "ridge_r2=[]\n",
    "for train_index, test_index in cv.split(X_train_regr):\n",
    "    X_train, X_test = X_train_regr.iloc[train_index], X_train_regr.iloc[test_index], \n",
    "    y_train, y_test =y_train_regr.iloc[train_index], y_train_regr.iloc[test_index]\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred=ridge.predict(X_test)\n",
    "    ridge_mse.append(mean_squared_error(y_pred**3,y_test**3))\n",
    "    ridge_r2.append(r2_score(y_true=y_test**3, y_pred=y_pred**3))\n",
    "print(np.mean(ridge_mse))\n",
    "print(ridge_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.94188598096671\n",
      "[0.039869485192376763, 0.035575645179986015, 0.04939986700881338, 0.04693592377269584, 0.050529480735243326, 0.04522304103918029, 0.041089419401204585, 0.032863438091356945, 0.0323946051977676, 0.042397977570109435]\n"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgdr=SGDRegressor(loss=\"squared_loss\", penalty=\"l2\", max_iter=100)\n",
    "\n",
    "sgdr_mse = []\n",
    "# fold_max_conv_lm=[]\n",
    "# fold_min_conv_lm=[]\n",
    "sgdr_r2=[]\n",
    "for train_index, test_index in cv.split(X_train_regr):\n",
    "    X_train, X_test = X_train_regr.iloc[train_index], X_train_regr.iloc[test_index], \n",
    "    y_train, y_test =y_train_regr.iloc[train_index], y_train_regr.iloc[test_index]\n",
    "    sgdr.fit(X_train, y_train)\n",
    "    y_pred=sgdr.predict(X_test)\n",
    "    sgdr_mse.append(mean_squared_error(y_pred**3,y_test**3))\n",
    "    sgdr_r2.append(r2_score(y_true=y_test**3, y_pred=y_pred**3))\n",
    "print(np.mean(sgdr_mse))\n",
    "print(sgdr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.28747049996934\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "xgb_mse=[]\n",
    "xgb_test=[]\n",
    "xgb_pred=[]\n",
    "for train_index, test_index in cv.split(X_train_regr):\n",
    "    X_train, X_test = X_train_regr.iloc[train_index], X_train_regr.iloc[test_index], \n",
    "    y_train, y_test =y_train_regr.iloc[train_index], y_train_regr.iloc[test_index]\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred=xgb.predict(X_test)\n",
    "    xgb_test.append(y_test)\n",
    "    xgb_pred.append(y_pred)\n",
    "    xgb_mse.append(mean_squared_error(y_pred**3,y_test**3))\n",
    "print(np.mean(xgb_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regr_mse={'lm':np.mean(lm_mse),'logregl1':np.mean(lasso_mse),'logregl2':np.mean(ridge_mse), 'sgd':np.mean(sgdr_mse),'xgb':np.mean(xgb_mse)}\n",
    "regr_results=pd.DataFrame([regr_mse],index=['Mean Squared Error']).T\n",
    "regr_results.index=['LM','LM L1-Norm','LM L2-Norm','SGD','XGB']\n",
    "regr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mean Squared Error of models used')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAH9NJREFUeJzt3Xm4HVWZ7/HvjyQkYZAwHJogQ1BGCRDggHihAWNQRLGx1YsTAq2NTQuIA9dWUAZxoEWxFUWjCAEVQQTEMAitBgxqMJEQQAZBRpkCEiBBQgjv/WOtYyrbc/auM9TeJ6d+n+epJ7tWTW/VPtlv1VpVqxQRmJlZfa3W6QDMzKyznAjMzGrOicDMrOacCMzMas6JwMys5pwIzMxqzonARjRJh0ma3ek4BkPSkZIek7RY0vpt3vZ9kqaVmG+SpJA0uh1x9VfZ/agrJ4JhKP/RviBpg4by+fk/26QOxPQpSffmH6OHJF3Y7hiGWuHHa3HDcHCnY+shaQzwFeD1EbFWRDzZ6Zhs5HEiGL7uBd7VMyJpB2B8JwKRdChwCDAtItYCuoFfdCCOqs42J+Qf2Z6h1yQnaVSZsmYGsA//BIwDbuvncmalOREMX+cD7yuMHwqcV5xB0lhJp0t6IFcdfEvS+DxtXUkzJS2U9FT+vElh2VmSPivpBknPSrqm8QqkYDfg5xFxD0BEPBoR0wvr2kLSdXk910o6U9L387R9JT3UEPffL9Ml7S7pt5IWSXokL7t6Yd6Q9CFJfwL+lMu2zdv5q6Q7Jf3fwvzrS7pc0jOSbgReWfqIN5B0rqSzJF0paQnw2j7K1pF0Xj7W90s6QdJqeR2H5WN8hqS/Aif1sp2xkr4q6eE8fDWXbQ3cmWdbJOmXvSzbc1VzuKQH83f9H5J2k7QgH9czC/OvluO7X9LjOe51CtMPydOelHR8w7ZWk/Rfku7J0y+StF4fx+4wSX/OfxP3SnpPk2N8amF8pb8XSZ+Q9Je8njslva5MLM32w3oRER6G2QDcB0wj/QhsB4wCHgQ2BwKYlOf7KnA5sB6wNvAz4At52vrA24A18rQfA5cVtjELuAfYmnSlMQv4Yh/xvBf4K3Ac6WpgVMP035KqL8YCewPPAt/P0/YFHupt//LnXYE9gNHAJOB24NjCvAFcm/dxPLBmPhaH52V2AZ4Ats/z/wi4KM83GfgLMLuP/ZqU1z+6j+nnAk8De5JOmsb1UXYe8NN8nCcBdwHvz+s4DHgRODrHO76X7ZwC/A7YEOgCfgN8tmSMPdO/lWN5PfA8cFle38uBx4F98vz/BtwNvAJYC7gEOD9PexWwOH+HY/N3+mLhuzo2x7lJnv5t4ILGOPOxfwbYJk+b2PP99HGMTy2M70v+ewG2yd/1xoVtvLJELE33w0Mv30OnA/DQy5eyIhGcAHwB2J/0Yzg6/2ebBAhY0vMfIy/3GuDePtY5BXiqMD4LOKEw/p/A1U1ieg/wv3mbTwL/lcs3y//J1izM+0NKJoJetnMscGlhPICphfGDgV83LPNt4ERSwlwGbFuY9nlaJ4JFDcN2efq5wHkNy6xUlre5FHhVoeyDwKz8+TDggRbf9z3AAYXxNwD3NcTYKhG8vFD2JHBwYfwn5ORKqtL7z8K0bfIxGw18BvhRYdqawAusSAS3A68rTJ9YWPbvceblFpFORP4h8fVyPPtKBFuSktg0YEzDcs1iabofHv5xGJYt/PZ35wPXA1vQUC1EOnNcA5gnqadMpB8mJK0BnEFKIuvm6WtLGhURy/P4o4X1PUc6Q+xVRPwA+IFS4+VB+fNNpLPjpyJiSWH2+4FNy+xgrv74CulKYw3Sf+R5DbM9WPi8OfBqSYsKZaNJx6orfy7Of3+JMDaIiBf7mPZgi7INgNUbtnM/6Uy82TqKNu5l+Y1bLNPoscLnv/Uy3vPd9rat0aS2iI2LsUbEEknFxunNgUslvVQoW56XpWG5g4GPA2dLugH4WETc0Z8dioi7JR1Lqk7bXtLPgY9GxMMtYmm1H9bAbQTDWETcT2o0PoB0CV/0BOk/+PYRMSEP60RqzAX4GOls79UR8TLSZTKkZDGYmJZFxI+BBaSql0eAdSWtWZhts8LnJaQf+LTx1LjaVZh+FnAHsFWO81O9xFjsIvdB4LrCPvc09B4JLCRdnRSTUDGWgeite95i2ROkM9HNG7b5lxbrKOr5YSsu/3A/YuyP3rb1IilxPELh2OWTieLtqg8Cb2w49uMiorivAETEzyNiP9KZ+h3Ad/qIZ6W/D2CjhvX8MCL2YkW16GklYmm1H9bAiWD4ez+paqR4xk1EvET6z3WGpA0BJL1c0hvyLGuTEsWi3Ih24kADyA1/b5K0dm6keyOwPTAnJ6u5wMmSVpe0F3BgYfG7gHF5+TGk6q6xhelrk+qTF0vaFjiyRTgzga1zY+CYPOwmabt8pXMJcJKkNSS9itTIXpm8zYuAz+XjsznwUeD7/VjNBcAJkrqUGuw/08/l++MC4CNKDfxrkarOLsxXRBcDb5a0l1KD/Sms/BvxLdJ+bg6Q4/2Xxg1I+idJb8knB0tJ9fXLG+fL5gMHSFpP0kakqsGe9WwjaaqksaR2j78V1tMsllb7YQ18cIa5iLgnIub2MfkTpIa/30l6hlSHv02e9lVS4+oTpEa1qwcRxjOkM/UHSHW//w0cGRE9D2q9G3g1qUH5RArVWBHxNKn94buks+QlQPEuoo/n5Z8lJbamzydExLOkBtF3ks5uHyWdJfYkl6NI1SCPkuqfzymxf4u08nMEHy2xTNHRpP36MzCb1EbyvX4sfyopmS4AbgH+kMuq8D1WVDneS/qBPRogIm4DPkSK/xHgKVb+rv6HdHPCNZKeJf1dvbqXbaxGuiJ9mPQ3sQ/pb6A35wM3k9qNrmHl738s8EXS3/CjpMbvT7WKpcR+WAPlxhSzISPpJGDLiHhvp2Mxs9Z8RWBmVnOV3TUkaRzp8nNs3s7FEXGipF+T6oUhXerdGBEHVRWHmZk1V1nVkNI9jWtGxOLcSDgb+HBE/K4wz0+An0ZE462RZmbWJpVVDUWyOI+OycPfs46ktYGppCcgzcysQyp9oCzfMz6P9ITgNyJiTmHyW4FfRMQzfSx7BHAEwJprrrnrtttuW2WoZmYjzrx5856IiK5W87XlriFJE4BLgaMj4tZcdhXw3Yj4Savlu7u7Y+7cvu6gNDOz3kiaFxHdreZry11DEbGI1LfN/pB6iAR2B65ox/bNzKxvlSWC/KTfhPx5PKnjqJ6+Rt4BzIyI56vavpmZlVNlG8FEYEZuJ1gNuCgiZuZp7yQ9MWhmZh1WWSKIiAXAzn1M27eq7ZqZWf/4yWIzs5pzIjAzqzknAjOzmnMiMDOrOScCM7OacyIwM6s5JwIzs5qrtNM5a58HTtmh0yFUYrPP3NLpEMxGPF8RmJnVnBOBmVnNORGYmdWcE4GZWc05EZiZ1ZwTgZlZzTkRmJnVnBOBmVnNORGYmdWcE4GZWc05EZiZ1ZwTgZlZzTkRmJnVnBOBmVnNVZYIJI2TdKOkmyXdJunkXC5Jn5N0l6TbJR1TVQxmZtZale8jWApMjYjFksYAsyVdBWwHbApsGxEvSdqwwhjMzKyFyhJBRASwOI+OyUMARwLvjoiX8nyPVxWDmZm1VmkbgaRRkuYDjwPXRsQc4JXAwZLmSrpK0lZ9LHtEnmfuwoULqwzTzKzWKk0EEbE8IqYAmwC7S5oMjAWej4hu4DvA9/pYdnpEdEdEd1dXV5VhmpnVWlvuGoqIRcAsYH/gIeAnedKlwI7tiMHMzHpX5V1DXZIm5M/jgWnAHcBlwNQ82z7AXVXFYGZmrVV519BEYIakUaSEc1FEzJQ0G/iBpI+QGpM/UGEMZmbWQpV3DS0Adu6lfBHwpqq2a2Zm/eMni83Mas6JwMys5pwIzMxqzonAzKzmnAjMzGrOicDMrOacCMzMas6JwMys5pwIzMxqzonAzKzmnAjMzGrOicDMrOacCMzMas6JwMys5pwIzMxqzonAzKzmnAjMzGrOicDMrOacCMzMas6JwMys5pwIzMxqzonAzKzmKksEksZJulHSzZJuk3RyLj9X0r2S5udhSlUxmJlZa6MrXPdSYGpELJY0Bpgt6ao87biIuLjCbZuZWUlNrwgkjZL0vwNZcSSL8+iYPMRA1mVmZtVpmggiYjnwnKR1BrLynEjmA48D10bEnDzpc5IWSDpD0tg+lj1C0lxJcxcuXDiQzZuZWQll2gieB26RdLakr/UMZVYeEcsjYgqwCbC7pMnAJ4Ftgd2A9YBP9LHs9Ijojojurq6uUjtjZmb9V6aN4Io8DFhELJI0C9g/Ik7PxUslnQN8fDDrNjOzwWmZCCJihqTVga1z0Z0RsazVcpK6gGU5CYwHpgGnSZoYEY9IEnAQcOsg4jczs0FqmQgk7QvMAO4DBGwq6dCIuL7FohOBGZJGkaqgLoqImZJ+mZOEgPnAfwwifjMzG6QyVUNfBl4fEXcCSNoauADYtdlCEbEA2LmX8qkDiNPMzCpSprF4TE8SAIiIu0i3gpqZ2QhQ5opgrqSzgfPz+HuAedWFZGZm7VQmERwJfAg4hlSvfz3wzSqDMjOz9mmaCHJD79kR8V7gK+0JyczM2qnMk8Vd+fZRMzMbgcpUDd0H3CDpcmBJT2FE+ArBzGwEKJMIHs7DasDa1YZjZmbtVqaNYK2IOK5N8ZiZWZuVaSPYpU2xmJlZB5SpGpqf2wd+zMptBJdUFpWZmbVNmUSwHvAkUOwaIgAnAjOzEaBM76OHtyMQMzPrjD7bCCRdVPh8WsO0a6oMyszM2qdZY/FWhc/7NUzzK8PMzEaIZomg2Yvm/RJ6M7MRolkbwRqSdiYli/H5s/Iwvh3BmZlZ9ZolgkdY0dHco6zc6dyjlUVkZmZt1WciiIjXtjMQMzPrjDJvKDMzsxHMicDMrOacCMzMaq7PNgJJTTubi4g/DH04ZmbWbs3uGvpy/ncc0A3cTLp1dEdgDrBXsxVLGkd6v/HYvJ2LI+LEwvSvA4dHxFoDjt7MzAatz6qhiHhtvnPofmCXiOiOiF2BnYG7S6x7KTA1InYCpgD7S9oDQFI3MGHQ0ZuZ2aCVaSPYNiJu6RmJiFtJP+xNRbI4j47JQ+SX3XwJ+H8DiNfMzIZYmURwu6TvStpX0j6SvgPcXmblkkZJmg88DlwbEXOAo4DLI+KRgYdtZmZDpcz7CA4HjgQ+nMevB84qs/L8hrMpkiYAl0raG3gHsG+rZSUdARwBsNlmm5XZnJmZDUCZ9xE8L+lbwJURcedANhIRiyTNAl4LbAncLQlSf0Z3R8SWvSwzHZgO0N3d7U7uzAbgur336XQIldjn+us6HcKI0jIRSHoLqU5/dWALSVOAUyLiLS2W6wKW5SQwHpgGnBYRGxXmWdxbEjAbjD2/vmenQ6jEDUff0OkQbIQqUzV0IrA7MAsgIuZLmlRiuYnAjNw4vBpwUUTMHFiYfdv1uPOGepUdN+9L7+t0CGZWI2USwYsR8XSuyiktIhaQbjVtNo+fITAz67AyieBWSe8GRknaCjgG+E21YZmZWbuUuX30aGB70gNiPwSeBo6tMigzM2ufplcEuX7/5Ig4Dji+PSGZmVk7Nb0iyM8B7NqmWMzMrAPKtBHcJOly4MfAkp7CiLiksqjMzKxtyiSC9YAngamFsgCcCMzMRoAyTxYf3o5AzMysM8o8WTwOeD/pzqFxPeUR8W8VxmVmZm1S5vbR84GNgDcA1wGbAM9WGZSZmbVPmUSwZUR8GlgSETOANwE7VBuWmZm1S5lEsCz/u0jSZGAdYFJlEZmZWVuVuWtouqR1gU8DlwNrAZ+pNCozM2ubMncNfTd/vA54RbXhmJlZu5W5a6jXs/+IOGXowzEzs3YrUzW0pPB5HPBmSr6z2MzMhr8yVUNfLo5LOp3UVmBmZiNAmbuGGq2B2wrMzEaMMm0Et5D6FgIYBXQBbh8wMxshyrQRvLnw+UXgsYh4saJ4zMyszcokgsbuJF5WfH9xRPx1SCMyM7O2KpMI/gBsCjwFCJgAPJCnBW4vMDNbpZVpLL4aODAiNoiI9UlVRZdExBYR4SRgZraKK5MIdouIK3tGIuIqYJ9WC0kaJ+lGSTdLuk3Sybn87Fy2QNLFktYaePhmZjZYZRLBE5JOkDRJ0uaSjie9sayVpcDUiNgJmALsL2kP4CMRsVNE7EiqYjpqwNGbmdmglUkE7yLdMnopcBmwYS5rKpLFeXRMHiIingFQanEez4pbU83MrAPKPFn8V+DDALkX0kURUerHW9IoYB6wJfCNiJiTy88BDgD+CHxsYKGbmdlQ6POKQNJnJG2bP4+V9EvgbuAxSdPKrDwilkfEFNJbzXbP7zPoeQ/yxqQ+iw7uY/tHSJorae7ChQv7tVNmZlZes6qhg4E78+dD87wbkhqKP9+fjUTEImAWsH+hbDlwIfC2PpaZHhHdEdHd1dXVn82ZmVk/NEsELxSqgN4AXJDP8G+nXNcUXZIm5M/jgWnAnZK2zGUCDgTuGMwOmJnZ4DT7QV+aq3IeA14LfLwwbY0S654IzMjtBKsBFwFXAL+W9DLSw2k3A0cOJHAzMxsazRLBh4GLSXcMnRER9wJIOgC4qdWKI2IBsHMvk/YcQJxmZlaRPhNBvsNn217KrwSu/MclzMxsVTSQ9xGYmdkI4kRgZlZzTgRmZjVXphtqJP0fYFJx/og4r6KYzMysjco8D3A+8EpgPrA8FwfgRGBmNgKUuSLoBl5Vtn8hMzNbtZRpI7gV2KjqQMzMrDPKXBFsAPxR0o2kdwwAEBFvqSwqMzNrmzKJ4KSqgzAzs84p8z6C69oRiJmZdUbLNgJJe0j6vaTFkl6QtFzSM+0IzszMqlemsfhM0qsp/0R6teQHcpmZmY0ApR4oi4i7JY3KL5M5R9JvKo7LzMzapEwieE7S6sB8Sf8NPAKsWW1YZmbWLmWqhg7J8x0FLAE2pY/XS5qZ2aqnzF1D9+dXTU6MiJPbEJOZmbVRmb6GDgROB1YHtpA0BTjFD5SZ2arkzI/9rNMhVOKoLx846HWUqRo6CdgdWAQQEfNJPZGamdkIUCYRvBgRT1ceiZmZdUSZu4ZulfRuYJSkrYBjAN8+amY2QpS5Ijga2J7U4dwFwDPAsVUGZWZm7VPmrqHngOPzYGZmI0yfiUDS5c0WbHXXkKRxwPXA2LydiyPiREk/IL3sZhlwI/DBiFjW38DNzGxoNLsieA3wIKk6aA6gfq57KTA1IhZLGgPMlnQV8APgvXmeH5L6Ljqrn+s2M7Mh0iwRbATsR+pw7t3AFcAFEXFbmRXnV1suzqNj8hARcWXPPPllN5sMIG4zMxsifTYWR8TyiLg6Ig4F9gDuBmZJOrrsyiWNkjQfeBy4NiLmFKaNIXVfcXUfyx4haa6kuQsXLiy7STMz66emdw1JGivpX4HvAx8CvgZcUnblOZlMIZ317y5pcmHyN4HrI+LXfSw7PSK6I6K7q6ur7CbNzKyfmjUWzwAmA1cBJ0fErQPdSEQskjQL2J/0XMKJQBfwwYGu08zMhkazNoJDSL2Nbg0cI/29rVikuv6XNVuxpC5gWU4C44FpwGmSPgC8AXhdRLw02B0wM7PB6TMRRESZh82amQjMkDSKVAV1UUTMlPQicD/w25xcLomIUwa5LTMzG6BSbygbiIhYAOzcS3ll2zQzs/4b7Fm/mZmt4pwIzMxqzonAzKzmnAjMzGrOicDMrOacCMzMas6JwMys5pwIzMxqzonAzKzmnAjMzGrOicDMrOacCMzMas6JwMys5pwIzMxqzonAzKzmnAjMzGrOicDMrOacCMzMas6JwMys5pwIzMxqzonAzKzmnAjMzGquskQgaZykGyXdLOk2SSfn8qMk3S0pJG1Q1fbNzKyc0RWueykwNSIWSxoDzJZ0FXADMBOYVeG2zcyspMoSQUQEsDiPjslDRMRNAJKq2rSZmfVDpW0EkkZJmg88DlwbEXP6sewRkuZKmrtw4cLqgjQzq7lKE0FELI+IKcAmwO6SJvdj2ekR0R0R3V1dXdUFaWZWc225aygiFpHaBPZvx/bMzKy8Ku8a6pI0IX8eD0wD7qhqe2ZmNjBVXhFMBH4laQHwe1IbwUxJx0h6iFRdtEDSdyuMwczMWqjyrqEFwM69lH8N+FpV2zUzs/7xk8VmZjXnRGBmVnNOBGZmNedEYGZWc04EZmY150RgZlZzTgRmZjXnRGBmVnNOBGZmNedEYGZWc04EZmY150RgZlZzTgRmZjXnRGBmVnNOBGZmNedEYGZWc04EZmY150RgZlZzTgRmZjXnRGBmVnNOBGZmNedEYGZWc5UlAknjJN0o6WZJt0k6OZdvIWmOpD9JulDS6lXFYGZmrVV5RbAUmBoROwFTgP0l7QGcBpwREVsBTwHvrzAGMzNrobJEEMniPDomDwFMBS7O5TOAg6qKwczMWlNEVLdyaRQwD9gS+AbwJeB3EbFlnr4pcFVETO5l2SOAI/LoNsCdlQVazgbAEx2OYbjwsVjBx2IFH4sVhsux2DwiulrNNLrKCCJiOTBF0gTgUmC73mbrY9npwPQKw+sXSXMjorvTcQwHPhYr+Fis4GOxwqp2LNpy11BELAJmAXsAEyT1JKBNgIfbEYOZmfWuyruGuvKVAJLGA9OA24FfAW/Psx0K/LSqGMzMrLUqq4YmAjNyO8FqwEURMVPSH4EfSToVuAk4u8IYhtKwqaYaBnwsVvCxWMHHYoVV6lhU2lhsZmbDn58sNjOrOScCM7OacyJoIGlxL2UnSQpJWxbKPpLLOnqL2FDEK2lWY7mk9SX9StJiSWc22f6+eb0HFspmStp3wDs1QBUei/0kzZN0S/53ah/bHzbHYqhJOj53FbNA0nxJr5Y0WtLnc3cx8/NwfGGZ5bnsttzVzEclrdK/OZI2lXSvpPXy+Lp5fHNJW+Xv+578d/IrSXvn+Q6TtLBwPC6WtEZn92aFVfpLabNbgHcWxt8O/LFDsZQx2HifBz4NfLzEvA8Bx7ecqw/5hoIqDfZYPAEcGBE7kO50O7/JvMP9WPSbpNcAbwZ2iYgdSXcAPgicCmwM7BARU4B/JvUg0ONvETElIrYH9gMOAE5sa/BDLCIeBM4CvpiLvkhqGH4MuAKYHhGvjIhdgaOBVxQWv7BwPF4ADm5f5M05EZR3GfAvAJJeATwNLOxoRM0NKt6IWBIRs0kJoZWbgacl7dc4QdLrJN2Uz6a/J2lsLr9P0mckzQbekc/Ez5B0vaTbJe0m6ZJ8tnlq2bj7MNhjcVNE9Dzvchswrmc/ejHcj8VATASeiIilABHxBLAI+Hfg6Ih4Ppc/GxEn9baCiHic1FPAUZLUlqircwawh6Rjgb2ALwPvAX4bEZf3zBQRt0bEuY0LKz1HtSapr7VhwYmgvGeAByVNBt4FXNjheFppd7ynAicUCySNA84FDs5n06OBIwuzPB8Re0XEj/L4CxGxN/At0vMlHwImA4dJWn8QsQ3lsXgbcFPPj2IfhvOxGIhrgE0l3SXpm5L2IXUb80BEPFt2JRHxZ9JvzoYVxdkWEbEMOI6UEI6NiBeA7YE/tFj0YEnzgb8A6wE/qzTQfnAi6J8fkaoYDiJ1mTHctS3eiPg1gKR/LhRvA9wbEXfl8RnA3oXpjT/IPWdTtwC3RcQj+Qf3z8Cmgwxx0MdC0vak3nM/2Gy+VeBY9EvuPHJX0hn9QlKs+xbnkXR4rv9+UKkPsb6s6lcDPd4IPEJKzv9A0qWSbpV0SaH4wlyFthHpez2u+jDLcSLon58Bh5DOhJ7pdDAlDHm8kt5aaBhsbGz9HCvXj7f6T7+kYbznLPulwuee8cE+/DioYyFpE1ICeV9E3JPLVtVj0W8RsTwiZkXEicBRwIHAZpLWztPPyT9yTwO9tnPkarnlwONtCrsSkqaQ2jz2AD4iaSKpynCXnnki4q3AYaQz/5VEenjrZ6x8ItBRTgT9EBF/Az5B+k8+7FURb0Rcmhu8pkTE3IZp1wDrAjvlojuASVpxx84hwHVDFUt/DOZYKHWVcgXwyYi4obDOVfJY9JekbSRtVSiaQuoN+GzgzFzt1dPQ3euLpiR1kaq5zoxV+CnW3L5xFqlK6AFSj8qnAz8E9pT0lsLsze4K2gu4p7JA+6ntZxargDUkPVQY/0pxYqEOd7gYqnivkLQsf/5tRLxD0n3Ay4DVJR0EvD4iWt1t8zly/1ER8bykw4Ef5way35N+DKpSybEgNQBvCXxa0qdz+etzA2gznTwWQ2kt4Os5Ib4I3E2qJnoa+Cxwq6Rngb+Rqrx6GtbH5zrxMXm582n4TlZB/066qrw2j3+TdOa/O+nOqq9I+irpLqJnSe1FPQ6WtBfpBPyhvNyw4C4mzMxqzlVDZmY150RgZlZzTgRmZjXnRGBmVnNOBGZmNedEYLWm1Fvo+YXx0bmXyJn9XM99kjYY7DxmneBEYHW3BJis9F5tSE+M/qWD8Zi1nROBGVwFvCl/fhdwQc8ESetJukypH/7fSdoxl68v6Zrcm+i3KXQhIem9km7MXU98Ww1dS0taU9IVSn303ypp2HRHbPXkRGCWO6TLXSXsCMwpTDuZ1NvojsCngPNy+YnA7IjYmdRB3GYAkrYj9TO/Z+57Zzmpi+Ki/YGHI2KniJgMXF3NbpmV4y4mrPYiYoGkSaSrgSsbJu9F6nqaiPhlvhJYh9Rh2L/m8isk9fQt/zpST52/z93uj+cfO1m7BThd0mnAzJ7eSs06xYnALLmc1HnYvkCxv//eeg2Nhn+LBMyIiE/2taGIuEvSrqQ3dn1B0jURccqAojYbAq4aMku+B5wSEbc0lF9PrtpRevfwE7kb62L5G0k9jQL8Ani7pA3ztPUkbV5coaSNgeci4vuk5LMLZh3kKwIzICIeAv6nl0knAedIWgA8R3pnMaS2gwsk/YHUnfQDeT1/lHQCcI3Si9qXkd4udn9hnTsAX5L0Up5efFOZWdu591Ezs5pz1ZCZWc05EZiZ1ZwTgZlZzTkRmJnVnBOBmVnNORGYmdWcE4GZWc39f0GKu6p7s23bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=regr_results.index,y='Mean Squared Error', data=regr_results)\n",
    "plt.ylim([30,37])\n",
    "plt.xlabel('Models')\n",
    "plt.title('Mean Squared Error of models used')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-6bf5c8adf61e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Run the grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mgrid_regr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters_regr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macc_scorer_regr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mgrid_regr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_regr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_regr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_regr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Set the clf to the best combination of parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    394\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "# Choose the type of classifier. \n",
    "clf_conv_sgd = linear_model.SGDClassifier()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters_class = {'loss' :['hinge','log'],\n",
    "                    'alpha' :[0.0001,0.001,0.01,0.1]}\n",
    "\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer_class = make_scorer(accuracy_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_class = GridSearchCV(clf_conv_sgd, parameters_class, scoring=acc_scorer_class)\n",
    "grid_class= grid_class.fit(X, y)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_class.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "# bclf.fit(X, y)\n",
    "\n",
    "import xgboost as xgb\n",
    "xgb = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters_regr = { 'max_depth' : [3,4,5],\n",
    "                    'gamma' : ['0','0.5', '1', '2'],\n",
    "                    'min_child_weight':['1','2', '3', '5']}\n",
    "             \n",
    "            \n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer_regr = make_scorer(mean_squared_error)\n",
    "\n",
    "# Run the grid search\n",
    "grid_regr = GridSearchCV(xgb, parameters_regr, scoring=acc_scorer_regr)\n",
    "grid_regr = grid_regr.fit(X_train_regr, y_train_regr)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "regr = grid_regr.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "# bclf.fit(X, y)\n",
    "print(regr)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bynode=1, colsample_bytree=1, gamma='2',\n",
      "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight='5', missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='reg:squarederror',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=None, subsample=1, verbosity=1)\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
      "       validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters_regr = { 'max_depth' : [3,4,5],\n",
    "                    'gamma' : ['0','0.5', '1', '2'],\n",
    "                    'min_child_weight':['1','2', '3', '5']}\n",
    "             \n",
    "            \n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer_regr = make_scorer(mean_squared_error)\n",
    "\n",
    "# Run the grid search\n",
    "grid_regr = GridSearchCV(xgb, parameters_regr, scoring=acc_scorer_regr)\n",
    "grid_regr = grid_regr.fit(X_train_regr, y_train_regr)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "regr = grid_regr.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "# bclf.fit(X, y)\n",
    "print(regr)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement two part model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifer is SGD\n",
    "#regressor is XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized final two-part model\n",
    "\n",
    "clf_conv_sgd_2pm = linear_model.SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
    "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=None,\n",
    "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
    "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "\n",
    "import xgboost as xgb\n",
    "xgb_2pm = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma='2',\n",
    "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight='5', missing=None, n_estimators=100,\n",
    "       n_jobs=1, nthread=None, objective='reg:squarederror',\n",
    "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "       seed=None, silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/faculty/.local/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.586049171140893"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# twopm 1\n",
    "clf_conv_sgd_2pm.fit(X,y)\n",
    "xgb_2pm.fit(X_train_regr,y_train_regr)\n",
    "# dt.fit(X=X_train_regr,y=y_train_regr)\n",
    "\n",
    "clf_conv_sgd_2pm.predict(X_val)\n",
    "xgb_2pm.predict(X_val)\n",
    "val_results=pd.DataFrame({'true values':y_val,'classifier':clf_conv_sgd_2pm.predict(X_val),'conversions':(xgb_2pm.predict(X_val)**3)})\n",
    "val_results['predictions']=val_results['classifier']*val_results['conversions']\n",
    "val_results['rmse']=((val_results['true values']-val_results['predictions'])**2)\n",
    "(val_results['rmse'].mean()**0.5)\n",
    "\n",
    "# val_results=pd.DataFrame({'true values':y_val,'classifier':clf_conv_sgd_2pm.predict(X_val),'conversions':(dt.predict(X_val)**3)})\n",
    "# val_results['predictions']=val_results['classifier']*val_results['conversions']\n",
    "# val_results['rmse']=((val_results['true values']-val_results['predictions'])**2)\n",
    "# (val_results['rmse'].mean()**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.644092544936217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.687934058652458\n"
     ]
    }
   ],
   "source": [
    "#base model 1\n",
    "lm_final=LinearRegression()\n",
    "lm_final.fit(X,y)\n",
    "y_pred_lm_final=lm_final.predict(X_val)\n",
    "print(mean_squared_error(y_pred_lm_final,y_val)**0.5)\n",
    "\n",
    "#base model 2\n",
    "rf_final=RandomForestRegressor()\n",
    "rf_final.fit(X,y)\n",
    "y_pred_rf_final=rf_final.predict(X_val)\n",
    "print(mean_squared_error(y_pred_rf_final,y_val)**0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_importance(xgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on past data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on data\n",
    "\n",
    "# first, select only one keyword for measurement\n",
    "\n",
    "# second, clean dataset\n",
    "\n",
    "# second, get z-score valuee of CPC from 0.01 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing='test_dataset.csv'\n",
    "test=pd.read_csv(testing,sep=',',skiprows=2)\n",
    "test1=test[test['Search keyword']=='cheap insurance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/anaconda/envs/Python3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#get number of words column\n",
    "test1['No. of words']=test1['Search keyword'].apply(func.get_number_of_words)\n",
    "\n",
    "#round up conversions values\n",
    "test1['Conversions']=test1['Conversions'].apply(func.round_conv)\n",
    "\n",
    "## drop ad columns that are useless\n",
    "# ad_cols_to_drop=['Headline','Short headline', 'Long headline', 'Responsive Search Ad headline 1','Responsive Search Ad headline 2', 'Responsive Search Ad headline 3','Responsive Search Ad headline 4', 'Responsive Search Ad headline 5','Responsive Search Ad headline 6', 'Responsive Search Ad headline 7', 'Responsive Search Ad headline 8', 'Responsive Search Ad headline 9', 'Responsive Search Ad headline 10', 'Responsive Search Ad headline 11', 'Responsive Search Ad headline 12', 'Responsive Search Ad headline 13','Responsive Search Ad headline 14', 'Responsive Search Ad headline 15','Responsive Search Ad description 1', 'Responsive Search Ad description 2','Responsive Search Ad description 3','Responsive Search Ad description 4', 'Expanded text ad description 2', 'Description line 1','Description line 2','Ad']\n",
    "ad_cols_to_drop=['Headline','Short headline','Long headline','Description','Headline 1','Headline 2', 'Responsive Search Ad headline 1','Responsive Search Ad headline 2', 'Responsive Search Ad headline 3','Responsive Search Ad headline 4', 'Responsive Search Ad headline 5','Responsive Search Ad headline 6', 'Responsive Search Ad headline 7', 'Responsive Search Ad headline 8', 'Responsive Search Ad headline 9', 'Responsive Search Ad headline 10', 'Responsive Search Ad headline 11', 'Responsive Search Ad headline 12', 'Responsive Search Ad headline 13','Responsive Search Ad headline 14', 'Responsive Search Ad headline 15','Responsive Search Ad description 1', 'Responsive Search Ad description 2','Responsive Search Ad description 3','Responsive Search Ad description 4', 'Expanded text ad description 2', 'Description line 1','Description line 2','Ad','Expanded text ad headline 3']\n",
    "\n",
    "test1=test1.drop(test1[ad_cols_to_drop],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan():\n",
    "#     columns_fillna=['Headline','Description line 1','Description line 2','Display URL','Ad']\n",
    "    columns_fillna=['Display URL']\n",
    "    for i in columns_fillna:\n",
    "        test1[i]=test1[i].fillna('Insuro.co.uk')\n",
    "fill_nan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine headline variables:\n",
    "\n",
    "landing_page=['Path 1','Path 2']\n",
    "test1['landing_page']=''\n",
    "for i in landing_page:\n",
    "    test1['landing_page']+=test1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col_list=['Day','Path 1','Path 2','Business name','Currency','CTR','Avg. CPC','Cost','Avg. position', 'Cost / conv.', 'Conv. rate']\n",
    "test1.drop(drop_col_list,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'landing_page'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'landing_page'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-4df960080b3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#     text_ad_group.append(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landing_page'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Landing Page Group '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlanding_page_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/Python3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'landing_page'"
     ]
    }
   ],
   "source": [
    "# convert all text groups and landing page to Ad Group # and Landing Page #\n",
    "# 37 landing page groups\n",
    "# 226 text ad groups\n",
    "# text_ad_group=[]\n",
    "landing_page_group=[]\n",
    "\n",
    "for i in list(range(1,df['landing_page'].nunique()+1)):\n",
    "    i='Landing Page Group '+str(i)\n",
    "    landing_page_group.append(i)    \n",
    "    \n",
    "text_ad_group=pd.concat([pd.DataFrame(df['text_ads'].value_counts().sort_values(ascending=False)).reset_index(),pd.DataFrame(text_ad_group)], axis=1).drop(['text_ads'],axis=1).set_index('index').reset_index()\n",
    "text_ad_group.columns=['ad group','Text Ad Group']\n",
    "landing_page_group=pd.concat([pd.DataFrame(df['landing_page'].value_counts().sort_values(ascending=False)).reset_index(),pd.DataFrame(landing_page_group)], axis=1).drop(['landing_page'],axis=1).set_index('index').reset_index()\n",
    "landing_page_group.columns=['landing page','Landing Page']\n",
    "\n",
    "df=pd.merge(df,text_ad_group,left_on='text_ads',right_on='ad group').drop(['text_ads','ad group'],axis=1)\n",
    "df=pd.merge(df,landing_page_group,left_on='landing_page',right_on='landing page').drop(['landing_page','landing page'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f=pd.merge(test1,landing_page_group,left_on='landing_page',right_on='landing page').drop(['landing_page','landing page'],axis=1)\n",
    "get_dummies_list=['Search keyword match type','Day of week','Device','Network (with search partners)','Landing page experience','Expected click-through rate','Ad relevance','Landing Page','Display URL']\n",
    "test_f=pd.get_dummies(test_f, columns=get_dummies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpcs=test[test['Avg. CPC']>0]['Avg. CPC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add landing page experience columns\n",
    "# ad relevance columns\n",
    "# Expected click-through rate\n",
    "# Display URL\n",
    "# Landing page column\n",
    "to_append=['Landing page experience_Below average','Landing page experience_Average',\n",
    "'Expected click-through rate_Average','Expected click-through rate_Below average',\n",
    "'Ad relevance_Average','Ad relevance_Below average',\n",
    "'Landing Page_Landing Page Group 10','Landing Page_Landing Page Group 11','Landing Page_Landing Page Group 12','Landing Page_Landing Page Group 13','Landing Page_Landing Page Group 14',\n",
    "'Landing Page_Landing Page Group 15','Landing Page_Landing Page Group 16','Landing Page_Landing Page Group 17','Landing Page_Landing Page Group 18','Landing Page_Landing Page Group 19',\n",
    "'Landing Page_Landing Page Group 2','Landing Page_Landing Page Group 20','Landing Page_Landing Page Group 21','Landing Page_Landing Page Group 22','Landing Page_Landing Page Group 23',\n",
    "'Landing Page_Landing Page Group 24','Landing Page_Landing Page Group 25','Landing Page_Landing Page Group 26','Landing Page_Landing Page Group 27','Landing Page_Landing Page Group 28',\n",
    "'Landing Page_Landing Page Group 29','Landing Page_Landing Page Group 3','Landing Page_Landing Page Group 30','Landing Page_Landing Page Group 4','Landing Page_Landing Page Group 5',\n",
    "'Landing Page_Landing Page Group 6','Landing Page_Landing Page Group 7','Landing Page_Landing Page Group 8','Landing Page_Landing Page Group 9',\n",
    "'Display URL_Insuro.co.uk/Black-Box-Insurance','Display URL_Insuro.co.uk/Cheap-Car-Insurance','Display URL_Insuro.co.uk/Compare-Car-Insurance','Display URL_Insuro.co.uk/Get-Car-Insurance','Display URL_Insuro.co.uk/No-Deposit-Insurance',\n",
    "'Display URL_Insuro.co.uk/NoDepositCarInsurance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f.columns\n",
    "test_f.shape\n",
    "missing=[]\n",
    "for i in test_f.columns:\n",
    "    if i not in X.columns:\n",
    "        missing.append(i)\n",
    "test_f=test_f.drop(missing,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Standardized Column\n",
    "avgcpc_stddev=pd.DataFrame(df[df['Conversions']>0].groupby('Search keyword').agg(np.std, ddof=0)['Avg. CPC']).rename(index=str, columns={\"Avg. CPC\": \"Avg. CPC_StdDev\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheapins=df[df['Search keyword']=='cheap insurance']\n",
    "cpc_test=pd.DataFrame(np.arange(0.00,1.45,0.01),columns=['Avg. CPC'])\n",
    "cpc_test['mean']=np.mean(cheapins['Avg. CPC'])\n",
    "cpc_test['std']=np.std(cheapins['Avg. CPC'])\n",
    "cpc_test['Avg. CPC_zscore']=(cpc_test['Avg. CPC']-cpc_test['mean'])/cpc_test['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f['id']=np.arange(1,128,1)\n",
    "test_ff=pd.DataFrame(np.repeat(test_f.values,145,axis=0))\n",
    "test_ff.columns = test_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricez=pd.concat([cpc_test]*127, ignore_index=True)['Avg. CPC_zscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ff['Avg. CPC_zscore']=pricez\n",
    "final_test_df=test_ff.drop(['id'],axis=1)\n",
    "final_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df=final_test_df[X_train_regr.columns]\n",
    "test_ff['pred_bin']=clf_conv_sgd_2pm.predict(final_test_df)\n",
    "test_ff['pred_conv']=xgb_2pm.predict(final_test_df)**3\n",
    "test_ff['predictions']=test_ff['pred_bin']*test_ff['pred_conv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of words</th>\n",
       "      <th>Search keyword match type_Exact</th>\n",
       "      <th>Search keyword match type_Phrase</th>\n",
       "      <th>Day of week_Monday</th>\n",
       "      <th>Day of week_Saturday</th>\n",
       "      <th>Day of week_Sunday</th>\n",
       "      <th>Day of week_Thursday</th>\n",
       "      <th>Day of week_Tuesday</th>\n",
       "      <th>Day of week_Wednesday</th>\n",
       "      <th>Device_Mobile</th>\n",
       "      <th>...</th>\n",
       "      <th>Display URL_Insuro.co.uk/Cheap-Car-Insurance</th>\n",
       "      <th>Display URL_Insuro.co.uk/Compare-Car-Insurance</th>\n",
       "      <th>Display URL_Insuro.co.uk/Get-Car-Insurance</th>\n",
       "      <th>Display URL_Insuro.co.uk/No-Deposit-Insurance</th>\n",
       "      <th>Display URL_Insuro.co.uk/NoDepositCarInsurance</th>\n",
       "      <th>id</th>\n",
       "      <th>Avg. CPC_zscore</th>\n",
       "      <th>pred_bin</th>\n",
       "      <th>pred_conv</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.460818</td>\n",
       "      <td>1</td>\n",
       "      <td>5.628484</td>\n",
       "      <td>5.628484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.644795</td>\n",
       "      <td>1</td>\n",
       "      <td>4.331770</td>\n",
       "      <td>4.331770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.248495</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.198150</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.184689</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.120882</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.057076</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.006731</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.070537</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.134344</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.261957</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.376108</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.325763</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.389570</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.453376</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.517182</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.580989</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.312302</td>\n",
       "      <td>1</td>\n",
       "      <td>4.286405</td>\n",
       "      <td>4.286405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.439914</td>\n",
       "      <td>1</td>\n",
       "      <td>4.262302</td>\n",
       "      <td>4.262302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.567527</td>\n",
       "      <td>1</td>\n",
       "      <td>4.262302</td>\n",
       "      <td>4.262302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.631334</td>\n",
       "      <td>1</td>\n",
       "      <td>4.262302</td>\n",
       "      <td>4.262302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.695140</td>\n",
       "      <td>1</td>\n",
       "      <td>4.262302</td>\n",
       "      <td>4.262302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.503721</td>\n",
       "      <td>1</td>\n",
       "      <td>4.262302</td>\n",
       "      <td>4.262302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.708602</td>\n",
       "      <td>1</td>\n",
       "      <td>4.205638</td>\n",
       "      <td>4.205638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.758947</td>\n",
       "      <td>1</td>\n",
       "      <td>4.126505</td>\n",
       "      <td>4.126505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.822753</td>\n",
       "      <td>1</td>\n",
       "      <td>4.126505</td>\n",
       "      <td>4.126505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.205592</td>\n",
       "      <td>1</td>\n",
       "      <td>4.044114</td>\n",
       "      <td>4.044114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.141786</td>\n",
       "      <td>1</td>\n",
       "      <td>4.044114</td>\n",
       "      <td>4.044114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.397011</td>\n",
       "      <td>1</td>\n",
       "      <td>4.044114</td>\n",
       "      <td>4.044114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.333205</td>\n",
       "      <td>1</td>\n",
       "      <td>4.044114</td>\n",
       "      <td>4.044114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.516086</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.579893</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.090344</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.643699</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.707506</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.771312</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.835119</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.898925</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.962731</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.026538</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.069441</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.133247</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.431376</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.005635</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.367570</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.984731</td>\n",
       "      <td>0</td>\n",
       "      <td>1.846576</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.048538</td>\n",
       "      <td>0</td>\n",
       "      <td>1.846576</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.112344</td>\n",
       "      <td>0</td>\n",
       "      <td>1.846576</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.176150</td>\n",
       "      <td>0</td>\n",
       "      <td>1.786928</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.239957</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.303763</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.495183</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.941828</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.558989</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.622796</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.686602</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.750409</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.814215</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.878022</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.154151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.753949</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     No. of words  Search keyword match type_Exact  \\\n",
       "668             2                                0   \n",
       "635             2                                0   \n",
       "649             2                                0   \n",
       "642             2                                0   \n",
       "648             2                                0   \n",
       "647             2                                0   \n",
       "646             2                                0   \n",
       "645             2                                0   \n",
       "644             2                                0   \n",
       "643             2                                0   \n",
       "641             2                                0   \n",
       "651             2                                0   \n",
       "640             2                                0   \n",
       "639             2                                0   \n",
       "638             2                                0   \n",
       "637             2                                0   \n",
       "636             2                                0   \n",
       "650             2                                0   \n",
       "652             2                                0   \n",
       "654             2                                0   \n",
       "655             2                                0   \n",
       "656             2                                0   \n",
       "653             2                                0   \n",
       "634             2                                0   \n",
       "657             2                                0   \n",
       "658             2                                0   \n",
       "664             2                                0   \n",
       "663             2                                0   \n",
       "667             2                                0   \n",
       "666             2                                0   \n",
       "..            ...                              ...   \n",
       "590             2                                0   \n",
       "589             2                                0   \n",
       "581             2                                0   \n",
       "588             2                                0   \n",
       "587             2                                0   \n",
       "586             2                                0   \n",
       "585             2                                0   \n",
       "584             2                                0   \n",
       "583             2                                0   \n",
       "582             2                                0   \n",
       "597             2                                0   \n",
       "596             2                                0   \n",
       "607             2                                0   \n",
       "598             2                                0   \n",
       "608             2                                0   \n",
       "614             2                                0   \n",
       "613             2                                0   \n",
       "612             2                                0   \n",
       "611             2                                0   \n",
       "610             2                                0   \n",
       "609             2                                0   \n",
       "606             2                                0   \n",
       "599             2                                0   \n",
       "605             2                                0   \n",
       "604             2                                0   \n",
       "603             2                                0   \n",
       "602             2                                0   \n",
       "601             2                                0   \n",
       "600             2                                0   \n",
       "580             2                                0   \n",
       "\n",
       "     Search keyword match type_Phrase  Day of week_Monday  \\\n",
       "668                                 0                   0   \n",
       "635                                 0                   0   \n",
       "649                                 0                   0   \n",
       "642                                 0                   0   \n",
       "648                                 0                   0   \n",
       "647                                 0                   0   \n",
       "646                                 0                   0   \n",
       "645                                 0                   0   \n",
       "644                                 0                   0   \n",
       "643                                 0                   0   \n",
       "641                                 0                   0   \n",
       "651                                 0                   0   \n",
       "640                                 0                   0   \n",
       "639                                 0                   0   \n",
       "638                                 0                   0   \n",
       "637                                 0                   0   \n",
       "636                                 0                   0   \n",
       "650                                 0                   0   \n",
       "652                                 0                   0   \n",
       "654                                 0                   0   \n",
       "655                                 0                   0   \n",
       "656                                 0                   0   \n",
       "653                                 0                   0   \n",
       "634                                 0                   0   \n",
       "657                                 0                   0   \n",
       "658                                 0                   0   \n",
       "664                                 0                   0   \n",
       "663                                 0                   0   \n",
       "667                                 0                   0   \n",
       "666                                 0                   0   \n",
       "..                                ...                 ...   \n",
       "590                                 0                   0   \n",
       "589                                 0                   0   \n",
       "581                                 0                   0   \n",
       "588                                 0                   0   \n",
       "587                                 0                   0   \n",
       "586                                 0                   0   \n",
       "585                                 0                   0   \n",
       "584                                 0                   0   \n",
       "583                                 0                   0   \n",
       "582                                 0                   0   \n",
       "597                                 0                   0   \n",
       "596                                 0                   0   \n",
       "607                                 0                   0   \n",
       "598                                 0                   0   \n",
       "608                                 0                   0   \n",
       "614                                 0                   0   \n",
       "613                                 0                   0   \n",
       "612                                 0                   0   \n",
       "611                                 0                   0   \n",
       "610                                 0                   0   \n",
       "609                                 0                   0   \n",
       "606                                 0                   0   \n",
       "599                                 0                   0   \n",
       "605                                 0                   0   \n",
       "604                                 0                   0   \n",
       "603                                 0                   0   \n",
       "602                                 0                   0   \n",
       "601                                 0                   0   \n",
       "600                                 0                   0   \n",
       "580                                 0                   0   \n",
       "\n",
       "     Day of week_Saturday  Day of week_Sunday  Day of week_Thursday  \\\n",
       "668                     0                   0                     0   \n",
       "635                     0                   0                     0   \n",
       "649                     0                   0                     0   \n",
       "642                     0                   0                     0   \n",
       "648                     0                   0                     0   \n",
       "647                     0                   0                     0   \n",
       "646                     0                   0                     0   \n",
       "645                     0                   0                     0   \n",
       "644                     0                   0                     0   \n",
       "643                     0                   0                     0   \n",
       "641                     0                   0                     0   \n",
       "651                     0                   0                     0   \n",
       "640                     0                   0                     0   \n",
       "639                     0                   0                     0   \n",
       "638                     0                   0                     0   \n",
       "637                     0                   0                     0   \n",
       "636                     0                   0                     0   \n",
       "650                     0                   0                     0   \n",
       "652                     0                   0                     0   \n",
       "654                     0                   0                     0   \n",
       "655                     0                   0                     0   \n",
       "656                     0                   0                     0   \n",
       "653                     0                   0                     0   \n",
       "634                     0                   0                     0   \n",
       "657                     0                   0                     0   \n",
       "658                     0                   0                     0   \n",
       "664                     0                   0                     0   \n",
       "663                     0                   0                     0   \n",
       "667                     0                   0                     0   \n",
       "666                     0                   0                     0   \n",
       "..                    ...                 ...                   ...   \n",
       "590                     0                   0                     0   \n",
       "589                     0                   0                     0   \n",
       "581                     0                   0                     0   \n",
       "588                     0                   0                     0   \n",
       "587                     0                   0                     0   \n",
       "586                     0                   0                     0   \n",
       "585                     0                   0                     0   \n",
       "584                     0                   0                     0   \n",
       "583                     0                   0                     0   \n",
       "582                     0                   0                     0   \n",
       "597                     0                   0                     0   \n",
       "596                     0                   0                     0   \n",
       "607                     0                   0                     0   \n",
       "598                     0                   0                     0   \n",
       "608                     0                   0                     0   \n",
       "614                     0                   0                     0   \n",
       "613                     0                   0                     0   \n",
       "612                     0                   0                     0   \n",
       "611                     0                   0                     0   \n",
       "610                     0                   0                     0   \n",
       "609                     0                   0                     0   \n",
       "606                     0                   0                     0   \n",
       "599                     0                   0                     0   \n",
       "605                     0                   0                     0   \n",
       "604                     0                   0                     0   \n",
       "603                     0                   0                     0   \n",
       "602                     0                   0                     0   \n",
       "601                     0                   0                     0   \n",
       "600                     0                   0                     0   \n",
       "580                     0                   0                     0   \n",
       "\n",
       "     Day of week_Tuesday  Day of week_Wednesday  Device_Mobile  ...  \\\n",
       "668                    0                      0              1  ...   \n",
       "635                    0                      0              1  ...   \n",
       "649                    0                      0              1  ...   \n",
       "642                    0                      0              1  ...   \n",
       "648                    0                      0              1  ...   \n",
       "647                    0                      0              1  ...   \n",
       "646                    0                      0              1  ...   \n",
       "645                    0                      0              1  ...   \n",
       "644                    0                      0              1  ...   \n",
       "643                    0                      0              1  ...   \n",
       "641                    0                      0              1  ...   \n",
       "651                    0                      0              1  ...   \n",
       "640                    0                      0              1  ...   \n",
       "639                    0                      0              1  ...   \n",
       "638                    0                      0              1  ...   \n",
       "637                    0                      0              1  ...   \n",
       "636                    0                      0              1  ...   \n",
       "650                    0                      0              1  ...   \n",
       "652                    0                      0              1  ...   \n",
       "654                    0                      0              1  ...   \n",
       "655                    0                      0              1  ...   \n",
       "656                    0                      0              1  ...   \n",
       "653                    0                      0              1  ...   \n",
       "634                    0                      0              1  ...   \n",
       "657                    0                      0              1  ...   \n",
       "658                    0                      0              1  ...   \n",
       "664                    0                      0              1  ...   \n",
       "663                    0                      0              1  ...   \n",
       "667                    0                      0              1  ...   \n",
       "666                    0                      0              1  ...   \n",
       "..                   ...                    ...            ...  ...   \n",
       "590                    0                      0              1  ...   \n",
       "589                    0                      0              1  ...   \n",
       "581                    0                      0              1  ...   \n",
       "588                    0                      0              1  ...   \n",
       "587                    0                      0              1  ...   \n",
       "586                    0                      0              1  ...   \n",
       "585                    0                      0              1  ...   \n",
       "584                    0                      0              1  ...   \n",
       "583                    0                      0              1  ...   \n",
       "582                    0                      0              1  ...   \n",
       "597                    0                      0              1  ...   \n",
       "596                    0                      0              1  ...   \n",
       "607                    0                      0              1  ...   \n",
       "598                    0                      0              1  ...   \n",
       "608                    0                      0              1  ...   \n",
       "614                    0                      0              1  ...   \n",
       "613                    0                      0              1  ...   \n",
       "612                    0                      0              1  ...   \n",
       "611                    0                      0              1  ...   \n",
       "610                    0                      0              1  ...   \n",
       "609                    0                      0              1  ...   \n",
       "606                    0                      0              1  ...   \n",
       "599                    0                      0              1  ...   \n",
       "605                    0                      0              1  ...   \n",
       "604                    0                      0              1  ...   \n",
       "603                    0                      0              1  ...   \n",
       "602                    0                      0              1  ...   \n",
       "601                    0                      0              1  ...   \n",
       "600                    0                      0              1  ...   \n",
       "580                    0                      0              1  ...   \n",
       "\n",
       "     Display URL_Insuro.co.uk/Cheap-Car-Insurance  \\\n",
       "668                                             0   \n",
       "635                                             0   \n",
       "649                                             0   \n",
       "642                                             0   \n",
       "648                                             0   \n",
       "647                                             0   \n",
       "646                                             0   \n",
       "645                                             0   \n",
       "644                                             0   \n",
       "643                                             0   \n",
       "641                                             0   \n",
       "651                                             0   \n",
       "640                                             0   \n",
       "639                                             0   \n",
       "638                                             0   \n",
       "637                                             0   \n",
       "636                                             0   \n",
       "650                                             0   \n",
       "652                                             0   \n",
       "654                                             0   \n",
       "655                                             0   \n",
       "656                                             0   \n",
       "653                                             0   \n",
       "634                                             0   \n",
       "657                                             0   \n",
       "658                                             0   \n",
       "664                                             0   \n",
       "663                                             0   \n",
       "667                                             0   \n",
       "666                                             0   \n",
       "..                                            ...   \n",
       "590                                             0   \n",
       "589                                             0   \n",
       "581                                             0   \n",
       "588                                             0   \n",
       "587                                             0   \n",
       "586                                             0   \n",
       "585                                             0   \n",
       "584                                             0   \n",
       "583                                             0   \n",
       "582                                             0   \n",
       "597                                             0   \n",
       "596                                             0   \n",
       "607                                             0   \n",
       "598                                             0   \n",
       "608                                             0   \n",
       "614                                             0   \n",
       "613                                             0   \n",
       "612                                             0   \n",
       "611                                             0   \n",
       "610                                             0   \n",
       "609                                             0   \n",
       "606                                             0   \n",
       "599                                             0   \n",
       "605                                             0   \n",
       "604                                             0   \n",
       "603                                             0   \n",
       "602                                             0   \n",
       "601                                             0   \n",
       "600                                             0   \n",
       "580                                             0   \n",
       "\n",
       "     Display URL_Insuro.co.uk/Compare-Car-Insurance  \\\n",
       "668                                               0   \n",
       "635                                               0   \n",
       "649                                               0   \n",
       "642                                               0   \n",
       "648                                               0   \n",
       "647                                               0   \n",
       "646                                               0   \n",
       "645                                               0   \n",
       "644                                               0   \n",
       "643                                               0   \n",
       "641                                               0   \n",
       "651                                               0   \n",
       "640                                               0   \n",
       "639                                               0   \n",
       "638                                               0   \n",
       "637                                               0   \n",
       "636                                               0   \n",
       "650                                               0   \n",
       "652                                               0   \n",
       "654                                               0   \n",
       "655                                               0   \n",
       "656                                               0   \n",
       "653                                               0   \n",
       "634                                               0   \n",
       "657                                               0   \n",
       "658                                               0   \n",
       "664                                               0   \n",
       "663                                               0   \n",
       "667                                               0   \n",
       "666                                               0   \n",
       "..                                              ...   \n",
       "590                                               0   \n",
       "589                                               0   \n",
       "581                                               0   \n",
       "588                                               0   \n",
       "587                                               0   \n",
       "586                                               0   \n",
       "585                                               0   \n",
       "584                                               0   \n",
       "583                                               0   \n",
       "582                                               0   \n",
       "597                                               0   \n",
       "596                                               0   \n",
       "607                                               0   \n",
       "598                                               0   \n",
       "608                                               0   \n",
       "614                                               0   \n",
       "613                                               0   \n",
       "612                                               0   \n",
       "611                                               0   \n",
       "610                                               0   \n",
       "609                                               0   \n",
       "606                                               0   \n",
       "599                                               0   \n",
       "605                                               0   \n",
       "604                                               0   \n",
       "603                                               0   \n",
       "602                                               0   \n",
       "601                                               0   \n",
       "600                                               0   \n",
       "580                                               0   \n",
       "\n",
       "     Display URL_Insuro.co.uk/Get-Car-Insurance  \\\n",
       "668                                           0   \n",
       "635                                           0   \n",
       "649                                           0   \n",
       "642                                           0   \n",
       "648                                           0   \n",
       "647                                           0   \n",
       "646                                           0   \n",
       "645                                           0   \n",
       "644                                           0   \n",
       "643                                           0   \n",
       "641                                           0   \n",
       "651                                           0   \n",
       "640                                           0   \n",
       "639                                           0   \n",
       "638                                           0   \n",
       "637                                           0   \n",
       "636                                           0   \n",
       "650                                           0   \n",
       "652                                           0   \n",
       "654                                           0   \n",
       "655                                           0   \n",
       "656                                           0   \n",
       "653                                           0   \n",
       "634                                           0   \n",
       "657                                           0   \n",
       "658                                           0   \n",
       "664                                           0   \n",
       "663                                           0   \n",
       "667                                           0   \n",
       "666                                           0   \n",
       "..                                          ...   \n",
       "590                                           0   \n",
       "589                                           0   \n",
       "581                                           0   \n",
       "588                                           0   \n",
       "587                                           0   \n",
       "586                                           0   \n",
       "585                                           0   \n",
       "584                                           0   \n",
       "583                                           0   \n",
       "582                                           0   \n",
       "597                                           0   \n",
       "596                                           0   \n",
       "607                                           0   \n",
       "598                                           0   \n",
       "608                                           0   \n",
       "614                                           0   \n",
       "613                                           0   \n",
       "612                                           0   \n",
       "611                                           0   \n",
       "610                                           0   \n",
       "609                                           0   \n",
       "606                                           0   \n",
       "599                                           0   \n",
       "605                                           0   \n",
       "604                                           0   \n",
       "603                                           0   \n",
       "602                                           0   \n",
       "601                                           0   \n",
       "600                                           0   \n",
       "580                                           0   \n",
       "\n",
       "     Display URL_Insuro.co.uk/No-Deposit-Insurance  \\\n",
       "668                                              0   \n",
       "635                                              0   \n",
       "649                                              0   \n",
       "642                                              0   \n",
       "648                                              0   \n",
       "647                                              0   \n",
       "646                                              0   \n",
       "645                                              0   \n",
       "644                                              0   \n",
       "643                                              0   \n",
       "641                                              0   \n",
       "651                                              0   \n",
       "640                                              0   \n",
       "639                                              0   \n",
       "638                                              0   \n",
       "637                                              0   \n",
       "636                                              0   \n",
       "650                                              0   \n",
       "652                                              0   \n",
       "654                                              0   \n",
       "655                                              0   \n",
       "656                                              0   \n",
       "653                                              0   \n",
       "634                                              0   \n",
       "657                                              0   \n",
       "658                                              0   \n",
       "664                                              0   \n",
       "663                                              0   \n",
       "667                                              0   \n",
       "666                                              0   \n",
       "..                                             ...   \n",
       "590                                              0   \n",
       "589                                              0   \n",
       "581                                              0   \n",
       "588                                              0   \n",
       "587                                              0   \n",
       "586                                              0   \n",
       "585                                              0   \n",
       "584                                              0   \n",
       "583                                              0   \n",
       "582                                              0   \n",
       "597                                              0   \n",
       "596                                              0   \n",
       "607                                              0   \n",
       "598                                              0   \n",
       "608                                              0   \n",
       "614                                              0   \n",
       "613                                              0   \n",
       "612                                              0   \n",
       "611                                              0   \n",
       "610                                              0   \n",
       "609                                              0   \n",
       "606                                              0   \n",
       "599                                              0   \n",
       "605                                              0   \n",
       "604                                              0   \n",
       "603                                              0   \n",
       "602                                              0   \n",
       "601                                              0   \n",
       "600                                              0   \n",
       "580                                              0   \n",
       "\n",
       "     Display URL_Insuro.co.uk/NoDepositCarInsurance  id  Avg. CPC_zscore  \\\n",
       "668                                               0   5         1.460818   \n",
       "635                                               0   5        -0.644795   \n",
       "649                                               0   5         0.248495   \n",
       "642                                               0   5        -0.198150   \n",
       "648                                               0   5         0.184689   \n",
       "647                                               0   5         0.120882   \n",
       "646                                               0   5         0.057076   \n",
       "645                                               0   5        -0.006731   \n",
       "644                                               0   5        -0.070537   \n",
       "643                                               0   5        -0.134344   \n",
       "641                                               0   5        -0.261957   \n",
       "651                                               0   5         0.376108   \n",
       "640                                               0   5        -0.325763   \n",
       "639                                               0   5        -0.389570   \n",
       "638                                               0   5        -0.453376   \n",
       "637                                               0   5        -0.517182   \n",
       "636                                               0   5        -0.580989   \n",
       "650                                               0   5         0.312302   \n",
       "652                                               0   5         0.439914   \n",
       "654                                               0   5         0.567527   \n",
       "655                                               0   5         0.631334   \n",
       "656                                               0   5         0.695140   \n",
       "653                                               0   5         0.503721   \n",
       "634                                               0   5        -0.708602   \n",
       "657                                               0   5         0.758947   \n",
       "658                                               0   5         0.822753   \n",
       "664                                               0   5         1.205592   \n",
       "663                                               0   5         1.141786   \n",
       "667                                               0   5         1.397011   \n",
       "666                                               0   5         1.333205   \n",
       "..                                              ...  ..              ...   \n",
       "590                                               0   5        -3.516086   \n",
       "589                                               0   5        -3.579893   \n",
       "581                                               0   5        -4.090344   \n",
       "588                                               0   5        -3.643699   \n",
       "587                                               0   5        -3.707506   \n",
       "586                                               0   5        -3.771312   \n",
       "585                                               0   5        -3.835119   \n",
       "584                                               0   5        -3.898925   \n",
       "583                                               0   5        -3.962731   \n",
       "582                                               0   5        -4.026538   \n",
       "597                                               0   5        -3.069441   \n",
       "596                                               0   5        -3.133247   \n",
       "607                                               0   5        -2.431376   \n",
       "598                                               0   5        -3.005635   \n",
       "608                                               0   5        -2.367570   \n",
       "614                                               0   5        -1.984731   \n",
       "613                                               0   5        -2.048538   \n",
       "612                                               0   5        -2.112344   \n",
       "611                                               0   5        -2.176150   \n",
       "610                                               0   5        -2.239957   \n",
       "609                                               0   5        -2.303763   \n",
       "606                                               0   5        -2.495183   \n",
       "599                                               0   5        -2.941828   \n",
       "605                                               0   5        -2.558989   \n",
       "604                                               0   5        -2.622796   \n",
       "603                                               0   5        -2.686602   \n",
       "602                                               0   5        -2.750409   \n",
       "601                                               0   5        -2.814215   \n",
       "600                                               0   5        -2.878022   \n",
       "580                                               0   5        -4.154151   \n",
       "\n",
       "     pred_bin  pred_conv  predictions  \n",
       "668         1   5.628484     5.628484  \n",
       "635         1   4.331770     4.331770  \n",
       "649         1   4.286405     4.286405  \n",
       "642         1   4.286405     4.286405  \n",
       "648         1   4.286405     4.286405  \n",
       "647         1   4.286405     4.286405  \n",
       "646         1   4.286405     4.286405  \n",
       "645         1   4.286405     4.286405  \n",
       "644         1   4.286405     4.286405  \n",
       "643         1   4.286405     4.286405  \n",
       "641         1   4.286405     4.286405  \n",
       "651         1   4.286405     4.286405  \n",
       "640         1   4.286405     4.286405  \n",
       "639         1   4.286405     4.286405  \n",
       "638         1   4.286405     4.286405  \n",
       "637         1   4.286405     4.286405  \n",
       "636         1   4.286405     4.286405  \n",
       "650         1   4.286405     4.286405  \n",
       "652         1   4.262302     4.262302  \n",
       "654         1   4.262302     4.262302  \n",
       "655         1   4.262302     4.262302  \n",
       "656         1   4.262302     4.262302  \n",
       "653         1   4.262302     4.262302  \n",
       "634         1   4.205638     4.205638  \n",
       "657         1   4.126505     4.126505  \n",
       "658         1   4.126505     4.126505  \n",
       "664         1   4.044114     4.044114  \n",
       "663         1   4.044114     4.044114  \n",
       "667         1   4.044114     4.044114  \n",
       "666         1   4.044114     4.044114  \n",
       "..        ...        ...          ...  \n",
       "590         0   1.753949     0.000000  \n",
       "589         0   1.753949     0.000000  \n",
       "581         0   1.753949     0.000000  \n",
       "588         0   1.753949     0.000000  \n",
       "587         0   1.753949     0.000000  \n",
       "586         0   1.753949     0.000000  \n",
       "585         0   1.753949     0.000000  \n",
       "584         0   1.753949     0.000000  \n",
       "583         0   1.753949     0.000000  \n",
       "582         0   1.753949     0.000000  \n",
       "597         0   1.753949     0.000000  \n",
       "596         0   1.753949     0.000000  \n",
       "607         0   1.753949     0.000000  \n",
       "598         0   1.753949     0.000000  \n",
       "608         0   1.753949     0.000000  \n",
       "614         0   1.846576     0.000000  \n",
       "613         0   1.846576     0.000000  \n",
       "612         0   1.846576     0.000000  \n",
       "611         0   1.786928     0.000000  \n",
       "610         0   1.753949     0.000000  \n",
       "609         0   1.753949     0.000000  \n",
       "606         0   1.753949     0.000000  \n",
       "599         0   1.753949     0.000000  \n",
       "605         0   1.753949     0.000000  \n",
       "604         0   1.753949     0.000000  \n",
       "603         0   1.753949     0.000000  \n",
       "602         0   1.753949     0.000000  \n",
       "601         0   1.753949     0.000000  \n",
       "600         0   1.753949     0.000000  \n",
       "580         0   1.753949     0.000000  \n",
       "\n",
       "[145 rows x 58 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ff[test_ff['id']==5].sort_values(by='predictions',ascending=False)\n",
    "test_ff.groupby('id').max()['Avg. CPC_zscore'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370.8567065000534"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sun of total predictions\n",
    "sum(test_ff.groupby('id').max()['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8784327777629666"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.450818*np.std(cheapins['Avg. CPC'])+np.mean(cheapins['Avg. CPC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_conv_sgd_2pm.predict(X_val)\n",
    "# xgb_2pm.predict(X_val)\n",
    "val_results=pd.DataFrame({'true values':y_val,'classifier':clf_conv_sgd_2pm.predict(X_val),'conversions':(xgb_2pm.predict(X_val)**3)})\n",
    "val_results['predictions']=val_results['classifier']*val_results['conversions']\n",
    "val_results['rmse']=((val_results['true values']-val_results['predictions'])**2)\n",
    "(val_results['rmse'].mean()**0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
